{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ETF Trading Pipeline - Full End-to-End\n",
    "\n",
    "Single notebook that runs the entire pipeline:\n",
    "\n",
    "| Section | Description | Cache |\n",
    "|---------|-------------|-------|\n",
    "| 0 | Setup & Configuration | - |\n",
    "| 1 | Universe Discovery (~5,000 ETFs from NASDAQ + curated list) | `data/raw/etf_universe_qualified.csv` |\n",
    "| 2 | Historical Data Collection (IB + yfinance, resumable) | `data/processed/etf_prices_ib.parquet` |\n",
    "| 3 | Factor Scoring (Mom/Qual/Val/Vol) \u2014 leveraged filtered here | `data/factor_scores_latest.parquet` |\n",
    "| 4 | Portfolio Construction & Optimization | `~/trading/live_portfolio/target_portfolio_latest.csv` |\n",
    "| 5 | Backtesting & Performance Analysis | - |\n",
    "| 6 | Trade Recommendations ($70k reserve) | `~/trading/live_portfolio/trade_plan.csv` |\n",
    "| 7 | Edit Instructions & Claude Interpretation | - |\n",
    "| 8 | Trade Execution (IB Gateway) | `~/trading/live_portfolio/execution_log.csv` |\n",
    "\n",
    "Each section is independently runnable if cached data from prior steps exists.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s0-header",
   "metadata": {},
   "source": [
    "## Section 0: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s0-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# \u2500\u2500 Paths \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "DATA_DIR = Path.home() / \"trade_data\" / \"ETFTrader\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "IB_CACHE_DIR = DATA_DIR / \"ib_historical\"\n",
    "TRADING_DIR = Path.home() / \"trading\"\n",
    "LIVE_DIR = TRADING_DIR / \"live_portfolio\"\n",
    "ARCHIVE_DIR = LIVE_DIR / \"trade_plan_archive\"\n",
    "TRADE_PLAN_FILE = LIVE_DIR / \"trade_plan.csv\"\n",
    "\n",
    "for d in [PROCESSED_DIR, LIVE_DIR, ARCHIVE_DIR, IB_CACHE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# \u2500\u2500 IB Settings \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "IB_HOST = \"127.0.0.1\"\n",
    "IB_PORT = 4001\n",
    "IB_CLIENT_ID = 5\n",
    "\n",
    "# \u2500\u2500 Strategy Parameters \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "FACTOR_WEIGHTS = {\n",
    "    \"momentum\": 0.35,\n",
    "    \"quality\": 0.30,\n",
    "    \"value\": 0.15,\n",
    "    \"volatility\": 0.20,\n",
    "}\n",
    "NUM_POSITIONS = 20\n",
    "OPTIMIZER_TYPE = \"rankbased\"  # mvo | rankbased | simple | minvar\n",
    "CASH_RESERVE = 70_000\n",
    "TRAILING_STOP_PCT = 10\n",
    "STOP_LOSS_PCT = 0.12\n",
    "DRIFT_THRESHOLD = 0.05\n",
    "\n",
    "print(f\"Project:       {PROJECT_ROOT}\")\n",
    "print(f\"Data:          {DATA_DIR}\")\n",
    "print(f\"Trading:       {TRADING_DIR}\")\n",
    "print(f\"Optimizer:     {OPTIMIZER_TYPE}\")\n",
    "print(f\"Positions:     {NUM_POSITIONS}\")\n",
    "print(f\"Cash Reserve:  ${CASH_RESERVE:,}\")\n",
    "print(f\"Trailing Stop: {TRAILING_STOP_PCT}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Universe Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection.comprehensive_etf_list import (\n",
    "    COMPREHENSIVE_ETF_UNIVERSE,\n",
    "    get_all_tickers,\n",
    "    load_full_universe,\n",
    ")\n",
    "from data_collection.etf_filters import filter_leveraged_etfs, LEVERAGED_ETFS\n",
    "\n",
    "# \u2500\u2500 Load the FULL US ETF universe \u2500\u2500\n",
    "# Merges our curated ~790 categorized tickers with the NASDAQ trader file (~4,900+)\n",
    "all_tickers, categories = load_full_universe()\n",
    "\n",
    "curated_count = sum(1 for t in all_tickers if categories[t] != \"Uncategorized\")\n",
    "uncategorized_count = len(all_tickers) - curated_count\n",
    "leveraged_count = sum(1 for t in all_tickers if t in LEVERAGED_ETFS)\n",
    "\n",
    "print(f\"Full universe: {len(all_tickers)} ETFs\")\n",
    "print(f\"  Categorized (curated):  {curated_count}\")\n",
    "print(f\"  Uncategorized (NASDAQ): {uncategorized_count}\")\n",
    "print(f\"  Leveraged/inverse:      {leveraged_count} (kept for data collection)\")\n",
    "\n",
    "# Check for cached qualified universe\n",
    "qualified_path = RAW_DIR / \"etf_universe_qualified.csv\"\n",
    "if qualified_path.exists():\n",
    "    universe_df = pd.read_csv(qualified_path)\n",
    "    # Check if the cached universe is smaller than our full list (stale cache)\n",
    "    if len(universe_df) < len(all_tickers) * 0.8:\n",
    "        print(f\"\\nCached qualified universe ({len(universe_df)}) is much smaller \"\n",
    "              f\"than full universe ({len(all_tickers)}). Rebuilding...\")\n",
    "        universe_df = pd.DataFrame({\n",
    "            \"ticker\": all_tickers,\n",
    "            \"category\": [categories.get(t, \"Uncategorized\") for t in all_tickers],\n",
    "        })\n",
    "    else:\n",
    "        print(f\"\\nLoaded cached qualified universe: {len(universe_df)} tickers\")\n",
    "else:\n",
    "    universe_df = pd.DataFrame({\n",
    "        \"ticker\": all_tickers,\n",
    "        \"category\": [categories.get(t, \"Uncategorized\") for t in all_tickers],\n",
    "    })\n",
    "\n",
    "display(\n",
    "    Markdown(f\"### Universe: {len(universe_df)} ETFs across \"\n",
    "             f\"{universe_df['category'].nunique()} categories\")\n",
    ")\n",
    "display(universe_df.groupby(\"category\").size().sort_values(ascending=False).head(15).to_frame(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1-qualify",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: qualify contracts on IB to prune non-existent tickers\n",
    "# Set QUALIFY_ON_IB = True to run (takes ~2 min for 2500 tickers)\n",
    "QUALIFY_ON_IB = False\n",
    "\n",
    "if QUALIFY_ON_IB:\n",
    "    from ib_insync import IB, Stock\n",
    "\n",
    "    ib = IB()\n",
    "    try:\n",
    "        ib.connect(IB_HOST, IB_PORT, clientId=IB_CLIENT_ID, readonly=True, timeout=10)\n",
    "        print(f\"Connected: {ib.managedAccounts()[0]}\")\n",
    "\n",
    "        qualified, failed = [], []\n",
    "        tickers_to_check = universe_df[\"ticker\"].tolist()\n",
    "\n",
    "        for i in range(0, len(tickers_to_check), 50):\n",
    "            batch = tickers_to_check[i : i + 50]\n",
    "            for t in batch:\n",
    "                c = Stock(t, \"SMART\", \"USD\")\n",
    "                try:\n",
    "                    ib.qualifyContracts(c)\n",
    "                    if c.conId:\n",
    "                        qualified.append(t)\n",
    "                    else:\n",
    "                        failed.append(t)\n",
    "                except Exception:\n",
    "                    failed.append(t)\n",
    "            ib.sleep(0.5)\n",
    "            print(f\"\\r  {min(i + 50, len(tickers_to_check))}/{len(tickers_to_check)}\", end=\"\")\n",
    "\n",
    "        universe_df = pd.DataFrame(\n",
    "            {\"ticker\": qualified, \"category\": [categories.get(t, \"Unknown\") for t in qualified]}\n",
    "        )\n",
    "        universe_df.to_csv(qualified_path, index=False)\n",
    "        print(f\"\\nQualified: {len(qualified)}, Failed: {len(failed)}\")\n",
    "        ib.disconnect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"IB not available: {e}\")\n",
    "        print(\"Using unqualified universe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Historical Data Collection\n",
    "\n",
    "IB Gateway primary, yfinance fallback. Per-ticker parquet caching with smart resume:\n",
    "\n",
    "- **CURRENT** tickers (cached & up-to-date): skipped, no IB request\n",
    "- **STALE** tickers (cached but old): incremental update \u2014 fetches only the gap (e.g. last 30 days)\n",
    "- **MISSING** tickers (no cache): full 5Y download\n",
    "\n",
    "Set `RUN_COLLECTION = True` to connect to IB. Every ticker logs its action clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cached price data\n",
    "prices_ib_path = PROCESSED_DIR / \"etf_prices_ib.parquet\"\n",
    "prices_yf_path = PROCESSED_DIR / \"etf_prices_filtered.parquet\"\n",
    "\n",
    "prices = None\n",
    "\n",
    "if prices_ib_path.exists():\n",
    "    prices = pd.read_parquet(prices_ib_path)\n",
    "    print(f\"Loaded IB prices: {prices.shape[1]} tickers x {prices.shape[0]} days\")\n",
    "    print(f\"  Range: {prices.index[0].date()} to {prices.index[-1].date()}\")\n",
    "elif prices_yf_path.exists():\n",
    "    prices = pd.read_parquet(prices_yf_path)\n",
    "    print(f\"Loaded yfinance prices: {prices.shape[1]} tickers x {prices.shape[0]} days\")\n",
    "else:\n",
    "    # Try to build from individual parquets (e.g. after a partial IB download)\n",
    "    cached_parquets = list(IB_CACHE_DIR.glob(\"*.parquet\"))\n",
    "    cached_parquets = [f for f in cached_parquets if f.stem != \"manifest\"]\n",
    "    if len(cached_parquets) > 50:\n",
    "        print(f\"No consolidated file, but found {len(cached_parquets)} cached parquets. Building matrix...\")\n",
    "        from data_collection.ib_data_collector import IBDataCollector\n",
    "        # Build without IB connection \u2014 just reads parquets\n",
    "        class _DummyIB:\n",
    "            pass\n",
    "        _collector = IBDataCollector(ib=_DummyIB(), cache_dir=str(IB_CACHE_DIR))\n",
    "        prices = _collector.build_price_matrix()\n",
    "    else:\n",
    "        print(\"No cached prices. Set COLLECT_DATA = True below to download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2-collect",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Set to True to connect to IB and collect/update data.\n# The collector is SMART \u2014 it will:\n#   - SKIP tickers that are already up-to-date\n#   - INCREMENT stale tickers (fetch only the gap, e.g. last 30 days)\n#   - FULL DOWNLOAD only tickers with no cached data\n# ============================================================\nRUN_COLLECTION = True\nSCAN_IB = False          # Also discover ETFs via IB scanner\n# ============================================================\n\n# Force reload of the module (in case kernel has old version cached)\nimport importlib\nimport data_collection.ib_data_collector as _ib_mod\nimportlib.reload(_ib_mod)\nfrom data_collection.ib_data_collector import IBDataCollector, collect_with_fallback\n\ntickers = universe_df[\"ticker\"].tolist()\n\n# Show what we already have cached\ncached_parquets = [f.stem for f in IB_CACHE_DIR.glob(\"*.parquet\") if f.stem != \"manifest\"]\nprint(f\"Universe: {len(tickers)} tickers\")\nprint(f\"Already cached: {len(cached_parquets)} parquets in {IB_CACHE_DIR}\")\nprint(f\"Not yet cached: ~{len(set(tickers) - set(cached_parquets))} tickers\\n\")\n\n# Optionally expand universe via IB scanner\nif SCAN_IB:\n    try:\n        from ib_insync import IB\n        ib_scan = IB()\n        ib_scan.connect(IB_HOST, IB_PORT, clientId=IB_CLIENT_ID + 1, readonly=True, timeout=10)\n        collector_scan = IBDataCollector(ib=ib_scan, cache_dir=str(IB_CACHE_DIR))\n        scanned = collector_scan.scan_ib_etf_universe()\n        if scanned:\n            before = len(tickers)\n            tickers = sorted(set(tickers) | set(scanned))\n            print(f\"IB scanner expanded universe: {before} -> {len(tickers)} tickers\")\n        ib_scan.disconnect()\n    except Exception as e:\n        print(f\"IB scanner unavailable: {e}\")\n\nif RUN_COLLECTION:\n    try:\n        from ib_insync import IB\n\n        ib_data = IB()\n        ib_data.connect(IB_HOST, IB_PORT, clientId=IB_CLIENT_ID, readonly=True, timeout=10)\n        print(f\"Connected to IB: {ib_data.managedAccounts()[0]}\\n\")\n\n        collector = IBDataCollector(\n            ib=ib_data,\n            cache_dir=str(IB_CACHE_DIR),\n            rate_limit_interval=12.0,\n            duration=\"5 Y\",\n        )\n\n        # Single smart call: skips current, increments stale, downloads new\n        prices, results = collector.collect_universe(tickers)\n\n        ib_data.disconnect()\n\n    except Exception as e:\n        print(f\"\\nIB failed: {e}\")\n        if prices is None:\n            print(\"Falling back to yfinance for top 500 tickers...\")\n            import yfinance as yf\n            yf_tickers = [t for t in tickers if t not in cached_parquets][:500]\n            data = yf.download(\" \".join(yf_tickers), period=\"5y\", auto_adjust=True)\n            prices = data[\"Close\"].dropna(axis=1, how=\"all\")\n            prices.to_parquet(PROCESSED_DIR / \"etf_prices_ib.parquet\")\n        else:\n            print(f\"Using existing cached prices ({prices.shape[1]} tickers).\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prices is not None:\n",
    "    # Data quality filter\n",
    "    missing_pct = prices.isnull().sum() / len(prices) * 100\n",
    "    adequate = (prices.count() >= 252) & (missing_pct < 10)\n",
    "    before = len(prices.columns)\n",
    "    prices = prices.loc[:, adequate]\n",
    "    prices = prices.ffill().bfill()  # Forward-fill gaps\n",
    "\n",
    "    print(f\"Quality filter: {before} -> {len(prices.columns)} tickers\")\n",
    "    print(f\"Date range: {prices.index[0].date()} to {prices.index[-1].date()}\")\n",
    "    print(f\"Trading days: {len(prices)}\")\n",
    "else:\n",
    "    print(\"No price data available. Cannot proceed to factor scoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Factor Scoring\n",
    "\n",
    "4-factor model: Momentum (35%), Quality (30%), Value (15%), Volatility (20%)\n",
    "\n",
    "**Note:** Leveraged/inverse ETFs are filtered out HERE (not in data collection).\n",
    "All price data is kept for future leveraged strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3-factors",
   "metadata": {},
   "outputs": [],
   "source": [
    "from factors import (\n",
    "    FactorIntegrator,\n",
    "    MomentumFactor,\n",
    "    QualityFactor,\n",
    "    SimplifiedValueFactor,\n",
    "    VolatilityFactor,\n",
    ")\n",
    "\n",
    "factor_scores_path = DATA_DIR / \"factor_scores_latest.parquet\"\n",
    "\n",
    "# \u2500\u2500 Filter leveraged/inverse ETFs for the basic model \u2500\u2500\n",
    "# The full price data (including leveraged) is preserved for other strategies\n",
    "if prices is not None:\n",
    "    all_price_tickers = prices.columns.tolist()\n",
    "    basic_tickers = filter_leveraged_etfs(all_price_tickers)\n",
    "    prices_basic = prices[basic_tickers]\n",
    "    print(f\"Basic model universe: {len(basic_tickers)} tickers \"\n",
    "          f\"({len(all_price_tickers) - len(basic_tickers)} leveraged/inverse excluded)\")\n",
    "else:\n",
    "    prices_basic = prices\n",
    "\n",
    "# Check if recent scores exist (< 7 days old)\n",
    "recalculate = True\n",
    "if factor_scores_path.exists():\n",
    "    age_days = (datetime.now().timestamp() - factor_scores_path.stat().st_mtime) / 86400\n",
    "    if age_days < 7:\n",
    "        print(f\"Factor scores are {age_days:.1f} days old. Loading cached.\")\n",
    "        factor_df = pd.read_parquet(factor_scores_path)\n",
    "        combined_scores = factor_df.iloc[:, 0].sort_values(ascending=False)\n",
    "        recalculate = False\n",
    "    else:\n",
    "        print(f\"Factor scores are {age_days:.1f} days old. Recalculating.\")\n",
    "\n",
    "if recalculate and prices_basic is not None:\n",
    "    print(\"Calculating factor scores...\")\n",
    "\n",
    "    momentum_scores = MomentumFactor(lookback=252, skip_recent=21).calculate(prices_basic)\n",
    "    print(f\"  Momentum:   {momentum_scores.dropna().shape[0]} tickers\")\n",
    "\n",
    "    quality_scores = QualityFactor(lookback=252).calculate(prices_basic)\n",
    "    print(f\"  Quality:    {quality_scores.dropna().shape[0]} tickers\")\n",
    "\n",
    "    # Value factor needs expense ratios - use synthetic if unavailable\n",
    "    fundamentals_path = RAW_DIR / \"fundamentals.csv\"\n",
    "    if fundamentals_path.exists():\n",
    "        fund_df = pd.read_csv(fundamentals_path)\n",
    "        expense_ratios = fund_df.set_index(\"ticker\")[\"expense_ratio\"].dropna()\n",
    "        expense_ratios = expense_ratios.reindex(prices_basic.columns).fillna(expense_ratios.median())\n",
    "    else:\n",
    "        expense_ratios = pd.Series(\n",
    "            np.random.uniform(0.0005, 0.01, len(prices_basic.columns)),\n",
    "            index=prices_basic.columns,\n",
    "        )\n",
    "\n",
    "    value_scores = SimplifiedValueFactor().calculate(prices_basic, expense_ratios)\n",
    "    print(f\"  Value:      {value_scores.dropna().shape[0]} tickers\")\n",
    "\n",
    "    volatility_scores = VolatilityFactor(lookback=60).calculate(prices_basic)\n",
    "    print(f\"  Volatility: {volatility_scores.dropna().shape[0]} tickers\")\n",
    "\n",
    "    # Integrate\n",
    "    factor_df = pd.DataFrame(\n",
    "        {\n",
    "            \"momentum\": momentum_scores,\n",
    "            \"quality\": quality_scores,\n",
    "            \"value\": value_scores,\n",
    "            \"volatility\": volatility_scores,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    integrator = FactorIntegrator(factor_weights=FACTOR_WEIGHTS)\n",
    "    combined_scores = integrator.integrate(factor_df)\n",
    "\n",
    "    # Save\n",
    "    combined_scores.to_frame(\"integrated_score\").to_parquet(factor_scores_path)\n",
    "    print(f\"\\nIntegrated scores: {len(combined_scores)} tickers\")\n",
    "\n",
    "# Show top 30\n",
    "if 'combined_scores' in dir():\n",
    "    display(Markdown(\"### Top 30 ETFs by Integrated Score\"))\n",
    "    top30 = combined_scores.head(30).to_frame(\"score\")\n",
    "    top30[\"category\"] = [categories.get(t, \"\") for t in top30.index]\n",
    "    display(top30.style.format({\"score\": \"{:.4f}\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Portfolio Construction & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s4-optimize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio import (\n",
    "    MeanVarianceOptimizer,\n",
    "    MinVarianceOptimizer,\n",
    "    RankBasedOptimizer,\n",
    "    SimpleOptimizer,\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: {OPTIMIZER_TYPE.upper()}, Positions: {NUM_POSITIONS}\")\n",
    "\n",
    "# Use basic (non-leveraged) prices for optimization\n",
    "opt_prices = prices_basic if 'prices_basic' in dir() else prices\n",
    "\n",
    "if OPTIMIZER_TYPE == \"mvo\":\n",
    "    optimizer = MeanVarianceOptimizer(\n",
    "        num_positions=NUM_POSITIONS,\n",
    "        lookback=60,\n",
    "        risk_aversion=1.0,\n",
    "        use_factor_scores_as_alpha=True,\n",
    "        min_weight=0.03,\n",
    "        max_weight=0.08,\n",
    "    )\n",
    "    target_weights = optimizer.optimize(combined_scores, opt_prices)\n",
    "elif OPTIMIZER_TYPE == \"rankbased\":\n",
    "    optimizer = RankBasedOptimizer(\n",
    "        num_positions=NUM_POSITIONS,\n",
    "        weighting_scheme=\"exponential\",\n",
    "    )\n",
    "    target_weights = optimizer.optimize(combined_scores)\n",
    "elif OPTIMIZER_TYPE == \"minvar\":\n",
    "    optimizer = MinVarianceOptimizer(num_positions=NUM_POSITIONS, lookback=60)\n",
    "    target_weights = optimizer.optimize(combined_scores, opt_prices)\n",
    "else:\n",
    "    optimizer = SimpleOptimizer(num_positions=NUM_POSITIONS)\n",
    "    target_weights = optimizer.optimize(combined_scores)\n",
    "\n",
    "# Save\n",
    "target_weights.to_csv(LIVE_DIR / \"target_portfolio_latest.csv\", header=True)\n",
    "\n",
    "# Display\n",
    "port_info = pd.DataFrame(\n",
    "    {\n",
    "        \"weight\": target_weights,\n",
    "        \"score\": combined_scores[target_weights.index],\n",
    "        \"category\": [categories.get(t, \"\") for t in target_weights.index],\n",
    "    }\n",
    ").sort_values(\"weight\", ascending=False)\n",
    "\n",
    "display(Markdown(f\"### Target Portfolio ({len(target_weights)} positions)\"))\n",
    "display(port_info.style.format({\"weight\": \"{:.1%}\", \"score\": \"{:.4f}\"}))\n",
    "\n",
    "print(f\"\\nMax weight:  {target_weights.max():.1%}\")\n",
    "print(f\"Min weight:  {target_weights.min():.1%}\")\n",
    "print(f\"HHI:         {(target_weights**2).sum():.4f}\")\n",
    "\n",
    "# Expected volatility\n",
    "if opt_prices is not None and len(opt_prices) > 60:\n",
    "    available = [t for t in target_weights.index if t in opt_prices.columns]\n",
    "    if len(available) == len(target_weights):\n",
    "        ret = opt_prices[available].pct_change().dropna()\n",
    "        cov = ret.cov() * 252\n",
    "        w = target_weights[available].values\n",
    "        port_vol = np.sqrt(w @ cov.values @ w)\n",
    "        print(f\"Expected vol: {port_vol:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Backtesting & Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5-backtest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting import BacktestConfig, BacktestEngine, TransactionCostModel\n",
    "from portfolio import RankBasedOptimizer, StopLossManager, ThresholdRebalancer\n",
    "\n",
    "config = BacktestConfig(\n",
    "    initial_capital=1_000_000,\n",
    "    rebalance_frequency=\"weekly\",\n",
    "    num_positions=NUM_POSITIONS,\n",
    "    stop_loss_pct=STOP_LOSS_PCT,\n",
    "    use_stop_loss=True,\n",
    "    risk_free_rate=0.04,\n",
    ")\n",
    "\n",
    "cost_model = TransactionCostModel(\n",
    "    commission_per_trade=0.0,\n",
    "    spread_bps=2.0,\n",
    "    slippage_bps=2.0,\n",
    ")\n",
    "\n",
    "# Use basic (non-leveraged) prices for backtesting\n",
    "bt_prices = prices_basic if 'prices_basic' in dir() else prices\n",
    "\n",
    "# Build factor scores over time (static scores replicated across dates)\n",
    "factor_scores_bt = pd.DataFrame(\n",
    "    {col: combined_scores for col in bt_prices.index}\n",
    ").T\n",
    "factor_scores_bt.index = bt_prices.index\n",
    "\n",
    "bt_optimizer = RankBasedOptimizer(\n",
    "    num_positions=NUM_POSITIONS,\n",
    "    weighting_scheme=\"exponential\",\n",
    ")\n",
    "rebalancer = ThresholdRebalancer(drift_threshold=DRIFT_THRESHOLD)\n",
    "risk_manager = StopLossManager(position_stop_loss=STOP_LOSS_PCT)\n",
    "\n",
    "print(\"Running backtest...\")\n",
    "results = BacktestEngine(config, cost_model).run(\n",
    "    prices=bt_prices,\n",
    "    factor_scores=factor_scores_bt,\n",
    "    optimizer=bt_optimizer,\n",
    "    rebalancer=rebalancer,\n",
    "    risk_manager=risk_manager,\n",
    ")\n",
    "\n",
    "metrics = results[\"metrics\"]\n",
    "print(\"Done.\\n\")\n",
    "\n",
    "display(Markdown(\"### Backtest Results\"))\n",
    "for k in [\"cagr\", \"sharpe_ratio\", \"sortino_ratio\", \"max_drawdown\",\n",
    "          \"volatility\", \"win_rate\", \"total_return\", \"num_rebalances\"]:\n",
    "    v = metrics.get(k, 0)\n",
    "    if isinstance(v, float) and abs(v) < 10:\n",
    "        print(f\"  {k:<20} {v:+.2%}\" if \"ratio\" not in k else f\"  {k:<20} {v:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {k:<20} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "daily_values = results[\"daily_values\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), gridspec_kw={\"height_ratios\": [3, 1]})\n",
    "\n",
    "# Equity curve\n",
    "axes[0].plot(daily_values.index, daily_values.values, linewidth=1.5, color=\"steelblue\")\n",
    "axes[0].set_title(\"Equity Curve\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Portfolio Value ($)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"${x:,.0f}\"))\n",
    "\n",
    "# Drawdown\n",
    "running_max = daily_values.expanding().max()\n",
    "drawdown = (daily_values - running_max) / running_max\n",
    "axes[1].fill_between(drawdown.index, drawdown.values, 0, alpha=0.4, color=\"red\")\n",
    "axes[1].set_title(\"Drawdown\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Drawdown\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max drawdown: {drawdown.min():.1%} on {drawdown.idxmin().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Trade Recommendations\n",
    "\n",
    "Connects to IB, pulls live positions, compares vs target, generates trade plan.\n",
    "Enforces $70,000 cash reserve on all buy orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6-connect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ib_insync import IB, Order, Stock, LimitOrder, MarketOrder\n",
    "\n",
    "ib = IB()\n",
    "ib_connected = False\n",
    "try:\n",
    "    ib.connect(IB_HOST, IB_PORT, clientId=IB_CLIENT_ID, readonly=True, timeout=10)\n",
    "    print(f\"Connected: {ib.managedAccounts()[0]}\")\n",
    "    ib_connected = True\n",
    "except Exception as e:\n",
    "    print(f\"IB not available: {e}\")\n",
    "    print(\"Trade recommendations will be generated from target portfolio only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6-positions",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ib_connected:\n",
    "    # Pull account summary\n",
    "    summary = {}\n",
    "    for av in ib.accountSummary():\n",
    "        if av.currency == \"USD\":\n",
    "            try:\n",
    "                summary[av.tag] = float(av.value)\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "\n",
    "    nlv = summary.get(\"NetLiquidation\", 0)\n",
    "    cash = summary.get(\"TotalCashValue\", 0)\n",
    "\n",
    "    # Pull positions\n",
    "    ib_positions = [\n",
    "        {\"ticker\": p.contract.symbol, \"shares\": float(p.position), \"avg_cost\": float(p.avgCost)}\n",
    "        for p in ib.positions()\n",
    "    ]\n",
    "\n",
    "    # Fetch live prices\n",
    "    all_tickers_live = sorted(set(p[\"ticker\"] for p in ib_positions) | set(target_weights.index))\n",
    "    ib.reqMarketDataType(3)\n",
    "    live_prices = {}\n",
    "    qc = []\n",
    "    for t in all_tickers_live:\n",
    "        c = Stock(t, \"SMART\", \"USD\")\n",
    "        try:\n",
    "            ib.qualifyContracts(c)\n",
    "            if c.conId:\n",
    "                qc.append(c)\n",
    "        except Exception:\n",
    "            pass\n",
    "    snaps = [(c.symbol, ib.reqMktData(c, snapshot=True)) for c in qc]\n",
    "    ib.sleep(4)\n",
    "    for sym, td in snaps:\n",
    "        for attr in (\"last\", \"close\", \"bid\", \"ask\"):\n",
    "            v = getattr(td, attr, None)\n",
    "            if v is not None and v == v and v > 0:\n",
    "                live_prices[sym] = float(v)\n",
    "                break\n",
    "        ib.cancelMktData(td.contract)\n",
    "    ib.reqMarketDataType(1)\n",
    "\n",
    "    # Account overview\n",
    "    deployable = max(0, cash - CASH_RESERVE)\n",
    "    display(Markdown(f\"\"\"\n",
    "### Account Overview\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Net Liquidation | ${nlv:,.2f} |\n",
    "| Cash | ${cash:,.2f} |\n",
    "| Cash Reserve | ${CASH_RESERVE:,} |\n",
    "| Deployable Cash | ${deployable:,.2f} |\n",
    "| Positions | {len(ib_positions)} |\n",
    "\"\"\"))\n",
    "    print(f\"Got {len(live_prices)} live prices.\")\n",
    "else:\n",
    "    print(\"Skipping - IB not connected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6-trades",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = []\n",
    "\n",
    "if ib_connected:\n",
    "    # Build position data\n",
    "    targets = target_weights.to_dict()\n",
    "    ib_map = {}\n",
    "    pos_data = []\n",
    "\n",
    "    for pos in ib_positions:\n",
    "        t = pos[\"ticker\"]\n",
    "        if pos[\"shares\"] == 0:\n",
    "            continue\n",
    "        price = live_prices.get(t, pos[\"avg_cost\"])\n",
    "        mv = pos[\"shares\"] * price\n",
    "        tw = targets.get(t, 0)\n",
    "        aw = mv / nlv if nlv else 0\n",
    "        ib_map[t] = pos\n",
    "        pos_data.append({\n",
    "            \"ticker\": t, \"shares\": pos[\"shares\"],\n",
    "            \"price\": price, \"mkt_value\": mv,\n",
    "            \"target_w\": tw, \"actual_w\": aw,\n",
    "            \"drift\": aw - tw, \"in_target\": t in targets,\n",
    "        })\n",
    "\n",
    "    # 1. Sell non-targets\n",
    "    special = {\"IBKR\"}\n",
    "    for p in pos_data:\n",
    "        if not p[\"in_target\"] and p[\"ticker\"] not in special:\n",
    "            if p[\"shares\"] > 0:\n",
    "                trades.append({\"action\": \"SELL\", \"ticker\": p[\"ticker\"],\n",
    "                               \"shares\": int(abs(p[\"shares\"])), \"price\": round(p[\"price\"], 2),\n",
    "                               \"est_value\": round(abs(p[\"mkt_value\"]), 2),\n",
    "                               \"reason\": \"Not in strategy target\", \"instruction\": \"APPROVE\"})\n",
    "            elif p[\"shares\"] < 0:\n",
    "                trades.append({\"action\": \"BUY_TO_COVER\", \"ticker\": p[\"ticker\"],\n",
    "                               \"shares\": int(abs(p[\"shares\"])), \"price\": round(p[\"price\"], 2),\n",
    "                               \"est_value\": round(abs(p[\"mkt_value\"]), 2),\n",
    "                               \"reason\": \"Close short position\", \"instruction\": \"APPROVE\"})\n",
    "\n",
    "    # Cash reserve calculation\n",
    "    sell_proceeds = sum(t[\"est_value\"] for t in trades if t[\"action\"] == \"SELL\")\n",
    "    cover_cost = sum(t[\"est_value\"] for t in trades if t[\"action\"] == \"BUY_TO_COVER\")\n",
    "    available = max(0, cash + sell_proceeds - cover_cost - CASH_RESERVE)\n",
    "    print(f\"Available for buys: ${available:,.0f}\")\n",
    "\n",
    "    # 2. Buy candidates\n",
    "    buy_candidates = []\n",
    "    for ticker, tw in targets.items():\n",
    "        if ticker not in ib_map:\n",
    "            price = live_prices.get(ticker)\n",
    "            if price and price > 0:\n",
    "                sh = int(tw * nlv / price)\n",
    "                if sh > 0:\n",
    "                    buy_candidates.append({\"action\": \"BUY\", \"ticker\": ticker,\n",
    "                                           \"shares\": sh, \"price\": round(price, 2),\n",
    "                                           \"est_value\": round(sh * price, 2),\n",
    "                                           \"reason\": f\"New position (target {tw*100:.0f}%)\",\n",
    "                                           \"instruction\": \"APPROVE\"})\n",
    "\n",
    "    for p in pos_data:\n",
    "        if p[\"target_w\"] > 0 and abs(p[\"drift\"]) > 0.03:\n",
    "            diff = p[\"target_w\"] * nlv - p[\"mkt_value\"]\n",
    "            ds = int(abs(diff) / p[\"price\"])\n",
    "            if ds > 0:\n",
    "                if diff > 0:\n",
    "                    buy_candidates.append({\"action\": \"BUY\", \"ticker\": p[\"ticker\"],\n",
    "                                           \"shares\": ds, \"price\": round(p[\"price\"], 2),\n",
    "                                           \"est_value\": round(ds * p[\"price\"], 2),\n",
    "                                           \"reason\": f\"Rebalance (drift {p['drift']*100:+.1f}%)\",\n",
    "                                           \"instruction\": \"APPROVE\"})\n",
    "                else:\n",
    "                    trades.append({\"action\": \"SELL\", \"ticker\": p[\"ticker\"],\n",
    "                                   \"shares\": ds, \"price\": round(p[\"price\"], 2),\n",
    "                                   \"est_value\": round(ds * p[\"price\"], 2),\n",
    "                                   \"reason\": f\"Rebalance (drift {p['drift']*100:+.1f}%)\",\n",
    "                                   \"instruction\": \"APPROVE\"})\n",
    "\n",
    "    # Apply cash reserve cap\n",
    "    running_spend = 0\n",
    "    for bc in buy_candidates:\n",
    "        if running_spend + bc[\"est_value\"] <= available:\n",
    "            trades.append(bc)\n",
    "            running_spend += bc[\"est_value\"]\n",
    "        else:\n",
    "            remaining = available - running_spend\n",
    "            if remaining > bc[\"price\"]:\n",
    "                reduced = int(remaining / bc[\"price\"])\n",
    "                if reduced > 0:\n",
    "                    bc[\"shares\"] = reduced\n",
    "                    bc[\"est_value\"] = round(reduced * bc[\"price\"], 2)\n",
    "                    bc[\"reason\"] += f\" [capped by ${CASH_RESERVE:,} reserve]\"\n",
    "                    trades.append(bc)\n",
    "                    running_spend += bc[\"est_value\"]\n",
    "\n",
    "    trades.sort(key=lambda t: (0 if \"SELL\" in t[\"action\"] else 1, t[\"ticker\"]))\n",
    "\n",
    "    # Archive and save\n",
    "    if TRADE_PLAN_FILE.exists():\n",
    "        mtime = datetime.fromtimestamp(TRADE_PLAN_FILE.stat().st_mtime)\n",
    "        dest = ARCHIVE_DIR / f\"trade_plan_{mtime.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        shutil.copy2(TRADE_PLAN_FILE, dest)\n",
    "        print(f\"Archived previous plan: {dest.name}\")\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    with open(TRADE_PLAN_FILE, \"w\", newline=\"\") as f:\n",
    "        f.write(f\"# TRADE PLAN - Generated {ts}\\n#\\n\")\n",
    "        w = csv.DictWriter(f, fieldnames=[\"action\", \"ticker\", \"shares\", \"price\", \"est_value\", \"reason\", \"instruction\"])\n",
    "        w.writeheader()\n",
    "        for t in trades:\n",
    "            w.writerow(t)\n",
    "\n",
    "    total_buys = sum(t[\"est_value\"] for t in trades if \"BUY\" in t[\"action\"])\n",
    "    total_sells = sum(t[\"est_value\"] for t in trades if t[\"action\"] == \"SELL\")\n",
    "\n",
    "    display(Markdown(f\"### Trade Plan ({len(trades)} trades)\"))\n",
    "    display(pd.DataFrame(trades))\n",
    "    print(f\"\\nBuys: ${total_buys:,.0f}  |  Sells: ${total_sells:,.0f}  |  \"\n",
    "          f\"Cash after: ${cash + total_sells - total_buys:,.0f} (reserve: ${CASH_RESERVE:,})\")\n",
    "    print(f\"Saved: {TRADE_PLAN_FILE}\")\n",
    "else:\n",
    "    print(\"Skipping - IB not connected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Edit Instructions & Claude Interpretation\n",
    "\n",
    "Edit `custom_instructions` below. Claude interprets natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7-edit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EDIT YOUR INSTRUCTIONS HERE\n",
    "# Format: \"TICKER\": \"instruction\"\n",
    "# Everything not listed stays as APPROVE.\n",
    "#\n",
    "# Examples:\n",
    "#   \"BND\": \"SKIP\",\n",
    "#   \"DIM\": \"reduce to 30 shares\",\n",
    "#   \"EWU\": \"change to limit order at $45\",\n",
    "# ============================================================\n",
    "\n",
    "custom_instructions = {\n",
    "    # \"BND\": \"SKIP\",\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# Apply\n",
    "for t in trades:\n",
    "    if t[\"ticker\"] in custom_instructions:\n",
    "        t[\"instruction\"] = custom_instructions[t[\"ticker\"]]\n",
    "\n",
    "if trades:\n",
    "    display(Markdown(\"### Updated Trade Plan\"))\n",
    "    display(pd.DataFrame(trades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7-interpret",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def interpret_trades(trades):\n",
    "    \"\"\"Interpret instructions using Claude API or keyword fallback.\"\"\"\n",
    "    result = []\n",
    "    custom = [t for t in trades if t[\"instruction\"].upper() not in (\"APPROVE\", \"SKIP\", \"\")]\n",
    "\n",
    "    claude_map = {}\n",
    "    if custom:\n",
    "        api_key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "        if api_key:\n",
    "            try:\n",
    "                import anthropic\n",
    "\n",
    "                client = anthropic.Anthropic(api_key=api_key)\n",
    "                trade_lines = [\n",
    "                    f\"  - {t['action']} {t['shares']} shares of {t['ticker']} @ ${t['price']:.2f} | \"\n",
    "                    f\"User instruction: \\\"{t['instruction']}\\\"\"\n",
    "                    for t in custom\n",
    "                ]\n",
    "                prompt = (\n",
    "                    \"You are a trade execution assistant. Interpret each instruction into \"\n",
    "                    \"concrete trade parameters.\\n\\nReturn a JSON array of objects with: \"\n",
    "                    '\"ticker\", \"action\" (BUY/SELL/BUY_TO_COVER/SKIP), \"order_type\" '\n",
    "                    '(MARKET/LIMIT/STOP), \"shares\" (int), \"limit_price\" (number or null), '\n",
    "                    '\"stop_price\" (number or null), \"note\" (string).\\n\\n'\n",
    "                    f\"Trades:\\n{chr(10).join(trade_lines)}\\n\\nReturn ONLY the JSON array.\"\n",
    "                )\n",
    "                print(\"Sending to Claude...\")\n",
    "                msg = client.messages.create(\n",
    "                    model=\"claude-sonnet-4-5-20250929\",\n",
    "                    max_tokens=1024,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                )\n",
    "                text = msg.content[0].text.strip()\n",
    "                if text.startswith(\"```\"):\n",
    "                    text = text.split(\"```\")[1]\n",
    "                    if text.startswith(\"json\"):\n",
    "                        text = text[4:]\n",
    "                interpreted = json.loads(text)\n",
    "                claude_map = {i[\"ticker\"]: i for i in interpreted}\n",
    "                print(f\"Claude interpreted {len(interpreted)} trade(s).\")\n",
    "            except Exception as e:\n",
    "                print(f\"Claude failed: {e}. Using keyword fallback.\")\n",
    "        else:\n",
    "            print(\"No ANTHROPIC_API_KEY. Using keyword fallback.\")\n",
    "\n",
    "    for t in trades:\n",
    "        instr = t[\"instruction\"].upper()\n",
    "        if instr in (\"SKIP\", \"\"):\n",
    "            continue\n",
    "        if instr == \"APPROVE\":\n",
    "            result.append({\"ticker\": t[\"ticker\"], \"action\": t[\"action\"],\n",
    "                           \"order_type\": \"MARKET\", \"shares\": t[\"shares\"],\n",
    "                           \"limit_price\": None, \"stop_price\": None, \"note\": \"Approved\"})\n",
    "        elif t[\"ticker\"] in claude_map:\n",
    "            ci = claude_map[t[\"ticker\"]]\n",
    "            if ci[\"action\"] != \"SKIP\":\n",
    "                result.append(ci)\n",
    "            else:\n",
    "                print(f\"  Skipping {t['ticker']}: {ci.get('note', '')}\")\n",
    "        else:\n",
    "            il = t[\"instruction\"].lower()\n",
    "            if \"reduce\" in il:\n",
    "                m = re.search(r\"(\\d+)\\s*shares?\", il)\n",
    "                if m:\n",
    "                    result.append({\"ticker\": t[\"ticker\"], \"action\": t[\"action\"],\n",
    "                                   \"order_type\": \"MARKET\", \"shares\": int(m.group(1)),\n",
    "                                   \"limit_price\": None, \"stop_price\": None,\n",
    "                                   \"note\": f\"Reduced to {m.group(1)} shares\"})\n",
    "                    continue\n",
    "            if \"limit\" in il:\n",
    "                m = re.search(r\"\\$?([\\d.]+)\", il)\n",
    "                if m:\n",
    "                    result.append({\"ticker\": t[\"ticker\"], \"action\": t[\"action\"],\n",
    "                                   \"order_type\": \"LIMIT\", \"shares\": t[\"shares\"],\n",
    "                                   \"limit_price\": float(m.group(1)), \"stop_price\": None,\n",
    "                                   \"note\": f\"Limit @ ${m.group(1)}\"})\n",
    "                    continue\n",
    "            print(f\"  Cannot parse '{t['instruction']}' for {t['ticker']} - skipping\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "final_trades = interpret_trades(trades) if trades else []\n",
    "\n",
    "if final_trades:\n",
    "    display(Markdown(f\"### Execution Plan ({len(final_trades)} trades)\"))\n",
    "    display(pd.DataFrame(final_trades))\n",
    "else:\n",
    "    print(\"No trades to execute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s8-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Execute Trades\n",
    "\n",
    "**This places REAL orders on your IB account.**\n",
    "\n",
    "Set `CONFIRM = True` and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s8-execute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SET TO True TO EXECUTE TRADES\n",
    "# ============================================================\n",
    "CONFIRM = False\n",
    "# ============================================================\n",
    "\n",
    "if not CONFIRM:\n",
    "    print(\"Execution not confirmed. Set CONFIRM = True to execute.\")\n",
    "elif not final_trades:\n",
    "    print(\"No trades to execute.\")\n",
    "elif not ib_connected:\n",
    "    print(\"IB not connected. Cannot execute.\")\n",
    "else:\n",
    "    # Reconnect in read-write mode\n",
    "    ib.disconnect()\n",
    "    ib_rw = IB()\n",
    "    ib_rw.connect(IB_HOST, IB_PORT, clientId=IB_CLIENT_ID + 10, readonly=False, timeout=10)\n",
    "    print(f\"Connected for trading: {ib_rw.managedAccounts()[0]}\\n\")\n",
    "\n",
    "    exec_results = []\n",
    "    for t in final_trades:\n",
    "        if t[\"action\"] == \"SKIP\":\n",
    "            continue\n",
    "\n",
    "        ticker = t[\"ticker\"]\n",
    "        ib_action = \"BUY\" if t[\"action\"] in (\"BUY\", \"BUY_TO_COVER\") else \"SELL\"\n",
    "        shares = t[\"shares\"]\n",
    "        order_type = t.get(\"order_type\", \"MARKET\")\n",
    "\n",
    "        contract = Stock(ticker, \"SMART\", \"USD\")\n",
    "        try:\n",
    "            ib_rw.qualifyContracts(contract)\n",
    "        except Exception as e:\n",
    "            print(f\"  {ticker}: FAILED - {e}\")\n",
    "            exec_results.append({\"ticker\": ticker, \"status\": \"FAILED\", \"message\": str(e)})\n",
    "            continue\n",
    "\n",
    "        if order_type == \"LIMIT\" and t.get(\"limit_price\"):\n",
    "            order = LimitOrder(ib_action, shares, t[\"limit_price\"])\n",
    "        else:\n",
    "            order = MarketOrder(ib_action, shares)\n",
    "\n",
    "        print(f\"  {ib_action} {shares} {ticker} ({order_type})...\", end=\"\")\n",
    "        trade_obj = ib_rw.placeOrder(contract, order)\n",
    "        ib_rw.sleep(2)\n",
    "\n",
    "        status = trade_obj.orderStatus.status\n",
    "        fill = trade_obj.orderStatus.avgFillPrice\n",
    "        print(f\" {status}\" + (f\" @ ${fill:.2f}\" if fill else \"\"))\n",
    "\n",
    "        exec_results.append({\"ticker\": ticker, \"status\": status,\n",
    "                             \"order_id\": trade_obj.order.orderId, \"fill_price\": fill})\n",
    "\n",
    "        # Trailing stop for BUY fills\n",
    "        if (t[\"action\"] == \"BUY\"\n",
    "                and status in (\"Filled\", \"Submitted\", \"PreSubmitted\")\n",
    "                and fill and fill > 0):\n",
    "            ts_order = Order()\n",
    "            ts_order.action = \"SELL\"\n",
    "            ts_order.totalQuantity = shares\n",
    "            ts_order.orderType = \"TRAIL\"\n",
    "            ts_order.trailingPercent = TRAILING_STOP_PCT\n",
    "            ts_order.tif = \"GTC\"\n",
    "            ts_trade = ib_rw.placeOrder(contract, ts_order)\n",
    "            ib_rw.sleep(1)\n",
    "            init_stop = fill * (1 - TRAILING_STOP_PCT / 100)\n",
    "            print(f\"    Trailing stop {TRAILING_STOP_PCT}% (~${init_stop:.2f}): {ts_trade.orderStatus.status}\")\n",
    "\n",
    "    # Log\n",
    "    log_file = LIVE_DIR / \"execution_log.csv\"\n",
    "    file_exists = log_file.exists()\n",
    "    log_ts = datetime.now().isoformat()\n",
    "    with open(log_file, \"a\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            w.writerow([\"timestamp\", \"ticker\", \"status\", \"order_id\", \"fill_price\"])\n",
    "        for r in exec_results:\n",
    "            w.writerow([log_ts, r.get(\"ticker\"), r.get(\"status\"),\n",
    "                        r.get(\"order_id\", \"\"), r.get(\"fill_price\", \"\")])\n",
    "\n",
    "    # Summary\n",
    "    filled = sum(1 for r in exec_results if r[\"status\"] in (\"Filled\", \"Submitted\", \"PreSubmitted\"))\n",
    "    failed = sum(1 for r in exec_results if r[\"status\"] in (\"ERROR\", \"FAILED\"))\n",
    "    display(Markdown(\"### Execution Summary\"))\n",
    "    print(f\"Executed: {filled}  |  Failed: {failed}  |  Total: {len(exec_results)}\")\n",
    "    display(pd.DataFrame(exec_results))\n",
    "\n",
    "    ib_rw.disconnect()\n",
    "    print(\"\\nDisconnected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ib.isConnected():\n",
    "    ib.disconnect()\n",
    "    print(\"Disconnected from IB Gateway.\")\n",
    "else:\n",
    "    print(\"Already disconnected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}