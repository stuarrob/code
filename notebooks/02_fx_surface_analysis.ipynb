{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FX Volatility Surface Analysis\n",
    "\n",
    "Historical analysis of FX option volatility surfaces via SABR model calibration.\n",
    "\n",
    "| Section | Description |\n",
    "|---------|-------------|\n",
    "| 0 | Setup & Configuration |\n",
    "| 1 | Historical FX Options Data (Databento) |\n",
    "| 2 | FX Spot Data (IB Gateway) |\n",
    "| 3 | SABR Calibration |\n",
    "| 4 | ATM Vol (Alpha) Evolution |\n",
    "| 5 | Skew (Rho) Evolution |\n",
    "| 6 | Vol-of-Vol (Nu) Evolution |\n",
    "| 7 | Term Structure Heatmaps |\n",
    "| 8 | Spot vs SABR Overlay |\n",
    "\n",
    "**Data sources:**\n",
    "- FX option prices: Databento GLBX.MDP3 (CME futures options, 3 years)\n",
    "- FX spot rates: IB Gateway MIDPOINT (interbank, 3 years)\n",
    "- Implied vols: Computed via Black-76 from settlement prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2\n\nimport sys\nimport warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams.update({'figure.figsize': (14, 6), 'font.size': 11})\n\nPROJECT_ROOT = Path.cwd().parent\nsys.path.insert(0, str(PROJECT_ROOT / 'src'))\nsys.path.insert(0, str(PROJECT_ROOT / 'notebooks'))\n\nDATA_DIR = Path.home() / 'trade_data' / 'ETFTrader'\nFX_OPTIONS_DB_DIR = DATA_DIR / 'fx_options_db'\nFX_SPOT_DIR = DATA_DIR / 'fx_spot'\nFX_SABR_DIR = DATA_DIR / 'fx_sabr'\n\n# Date range for analysis\nSTART_DATE = '2023-02-20'\nEND_DATE = '2026-02-20'\n\n# Currencies to analyse (CHF excluded — insufficient Databento data)\nCURRENCIES = ['EUR', 'GBP', 'AUD', 'CAD', 'JPY']\n\n# Tenor buckets of interest\nTENORS = ['1M', '3M', '6M', '1Y']\n\nprint(f'Data dir:   {DATA_DIR}')\nprint(f'Date range: {START_DATE} to {END_DATE}')\nprint(f'Currencies: {CURRENCIES}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Historical FX Options Data (Databento)\n",
    "\n",
    "Fetch 3 years of CME FX futures option data from Databento.\n",
    "Settlement prices are converted to implied vols via Black-76.\n",
    "\n",
    "Set `RUN_COLLECTION = True` for initial fetch (~$13, takes ~30 min).\n",
    "Subsequent runs load from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s', datefmt='%H:%M:%S')\n",
    "\n",
    "RUN_COLLECTION = False  # Set True for initial Databento fetch\n",
    "\n",
    "if RUN_COLLECTION:\n",
    "    from data_collection.databento_fx_collector import DatabentoFXCollector\n",
    "    collector = DatabentoFXCollector()\n",
    "    surface = collector.fetch_history(\n",
    "        currencies=CURRENCIES,\n",
    "        start=START_DATE,\n",
    "        end=END_DATE,\n",
    "    )\n",
    "else:\n",
    "    # Load from cache\n",
    "    dfs = []\n",
    "    for ccy in CURRENCIES:\n",
    "        path = FX_OPTIONS_DB_DIR / f'{ccy}_surface.parquet'\n",
    "        if path.exists():\n",
    "            df = pd.read_parquet(path)\n",
    "            dfs.append(df)\n",
    "            print(f'  {ccy}: {len(df)} rows, {df[\"timestamp\"].nunique()} dates')\n",
    "        else:\n",
    "            print(f'  {ccy}: no cached data')\n",
    "    surface = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "if not surface.empty:\n",
    "    surface['timestamp'] = pd.to_datetime(surface['timestamp'])\n",
    "    print(f'\\nTotal surface: {len(surface)} rows')\n",
    "    print(f'  Currencies: {sorted(surface[\"currency\"].unique())}')\n",
    "    print(f'  Date range: {surface[\"timestamp\"].min().date()} to {surface[\"timestamp\"].max().date()}')\n",
    "    print(f'  Valid IVs:  {surface[\"impliedVol\"].notna().sum()} / {len(surface)}')\n",
    "else:\n",
    "    print('No surface data! Set RUN_COLLECTION = True.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: FX Spot Data (IB Gateway)\n",
    "\n",
    "Collect 3 years of FX spot midpoint rates from IB.\n",
    "Set `RUN_SPOT_COLLECTION = True` with IB Gateway running for initial fetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_SPOT_COLLECTION = False  # Set True with IB Gateway running\n",
    "\n",
    "if RUN_SPOT_COLLECTION:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    from ib_insync import IB\n",
    "    from data_collection.fx_spot_collector import FXSpotCollector\n",
    "\n",
    "    ib = IB()\n",
    "    ib.connect('127.0.0.1', 4001, clientId=25, readonly=True, timeout=10)\n",
    "    print(f'Connected: {ib.managedAccounts()[0]}')\n",
    "\n",
    "    spot_collector = FXSpotCollector(ib, cache_dir=str(FX_SPOT_DIR))\n",
    "    spots, results = spot_collector.collect_all_extended(years=3)\n",
    "    ib.disconnect()\n",
    "else:\n",
    "    print('Loading spot data from cache...')\n",
    "\n",
    "# Build spot matrix from cache (works whether we just collected or not)\n",
    "from data_collection.fx_spot_collector import FXSpotCollector, FX_PAIRS\n",
    "\n",
    "spot_dfs = []\n",
    "for ccy, pair in FX_PAIRS.items():\n",
    "    path = FX_SPOT_DIR / f'{pair}.parquet'\n",
    "    if path.exists():\n",
    "        df = pd.read_parquet(path)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        spot_dfs.append(df[['date', 'currency', 'close']].copy())\n",
    "        print(f'  {pair}: {len(df)} bars ({df[\"date\"].min().date()} to {df[\"date\"].max().date()})')\n",
    "\n",
    "if spot_dfs:\n",
    "    spot_all = pd.concat(spot_dfs, ignore_index=True)\n",
    "    spot_matrix = spot_all.pivot_table(index='date', columns='currency', values='close').sort_index()\n",
    "    print(f'\\nSpot matrix: {spot_matrix.shape[1]} pairs x {len(spot_matrix)} days')\n",
    "else:\n",
    "    spot_matrix = pd.DataFrame()\n",
    "    print('No spot data cached. Set RUN_SPOT_COLLECTION = True with IB Gateway.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: SABR Calibration\n",
    "\n",
    "Fit the simplified SABR model (beta=1, lognormal) to each daily surface slice.\n",
    "Extracts alpha (ATM vol), rho (skew), nu (vol-of-vol) per (date, currency, tenor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fx_options.sabr import calibrate_surface, assign_tenor_bucket\n",
    "\n",
    "# Run SABR calibration\n",
    "sabr_params = calibrate_surface(surface, min_strikes=5, use_mid_iv=True)\n",
    "\n",
    "if not sabr_params.empty:\n",
    "    # Add time-scaled metrics\n",
    "    sabr_params['T'] = sabr_params['dte'].clip(lower=1) / 365.0\n",
    "    sabr_params['nu_sqrt_T'] = sabr_params['nu'] * np.sqrt(sabr_params['T'])\n",
    "    sabr_params['timestamp'] = pd.to_datetime(sabr_params['timestamp'])\n",
    "    sabr_params['date'] = sabr_params['timestamp'].dt.date\n",
    "\n",
    "    # Save historical SABR parameters\n",
    "    FX_SABR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    sabr_path = FX_SABR_DIR / 'sabr_params_historical.parquet'\n",
    "    sabr_params.to_parquet(sabr_path, index=False)\n",
    "\n",
    "    print(f'SABR calibration: {len(sabr_params)} slices')\n",
    "    print(f'  Success rate: {sabr_params[\"calibration_success\"].mean()*100:.0f}%')\n",
    "    print(f'  Median RMSE: {sabr_params[\"rmse\"].median():.6f}')\n",
    "    print(f'  Date range: {sabr_params[\"timestamp\"].min().date()} to {sabr_params[\"timestamp\"].max().date()}')\n",
    "    print(f'  Currencies: {sorted(sabr_params[\"currency\"].unique())}')\n",
    "    print(f'  Saved: {sabr_path}')\n",
    "else:\n",
    "    print('No SABR results — check surface data above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: ATM Vol (Alpha) Evolution\n",
    "\n",
    "Alpha is the ATM implied volatility in the SABR model.\n",
    "Shows how overall vol levels have evolved by currency and tenor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ncols = 3\nnrows = (len(CURRENCIES) + ncols - 1) // ncols\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 5 * nrows), sharex=True)\naxes = axes.flatten()\n\nfor idx, ccy in enumerate(CURRENCIES):\n    ax = axes[idx]\n    ccy_data = sabr_params[sabr_params['currency'] == ccy]\n\n    for tenor in TENORS:\n        tenor_data = ccy_data[ccy_data['tenor_bucket'] == tenor].sort_values('timestamp')\n        if not tenor_data.empty:\n            # Rolling median to smooth day-to-day noise\n            ts = tenor_data.set_index('timestamp')['alpha'].resample('W').median()\n            ax.plot(ts.index, ts.values * 100, label=tenor, linewidth=1.2)\n\n    ax.set_title(f'{ccy}/USD', fontweight='bold')\n    ax.set_ylabel('Alpha (ATM Vol %)')\n    ax.legend(fontsize=9)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    ax.tick_params(axis='x', rotation=45)\n\n# Hide unused subplots\nfor idx in range(len(CURRENCIES), len(axes)):\n    axes[idx].set_visible(False)\n\nfig.suptitle('SABR Alpha (ATM Vol) by Currency and Tenor', fontsize=14, fontweight='bold')\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Skew (Rho) Evolution\n",
    "\n",
    "Rho captures the correlation between spot and volatility — the skew direction.\n",
    "Negative rho = downside skew (puts more expensive than calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ncols = 3\nnrows = (len(CURRENCIES) + ncols - 1) // ncols\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 5 * nrows), sharex=True)\naxes = axes.flatten()\n\nfor idx, ccy in enumerate(CURRENCIES):\n    ax = axes[idx]\n    ccy_data = sabr_params[sabr_params['currency'] == ccy]\n\n    for tenor in TENORS:\n        tenor_data = ccy_data[ccy_data['tenor_bucket'] == tenor].sort_values('timestamp')\n        if not tenor_data.empty:\n            ts = tenor_data.set_index('timestamp')['rho'].resample('W').median()\n            ax.plot(ts.index, ts.values, label=tenor, linewidth=1.2)\n\n    ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n    ax.set_title(f'{ccy}/USD', fontweight='bold')\n    ax.set_ylabel('Rho (Skew)')\n    ax.legend(fontsize=9)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    ax.tick_params(axis='x', rotation=45)\n\nfor idx in range(len(CURRENCIES), len(axes)):\n    axes[idx].set_visible(False)\n\nfig.suptitle('SABR Rho (Skew) by Currency and Tenor', fontsize=14, fontweight='bold')\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Vol-of-Vol (Nu) Evolution\n",
    "\n",
    "Nu captures the curvature of the smile.\n",
    "Nu * sqrt(T) should be approximately constant across tenors if the model is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ncols = 3\nnrows = (len(CURRENCIES) + ncols - 1) // ncols\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 5 * nrows), sharex=True)\naxes = axes.flatten()\n\nfor idx, ccy in enumerate(CURRENCIES):\n    ax = axes[idx]\n    ccy_data = sabr_params[sabr_params['currency'] == ccy]\n\n    for tenor in TENORS:\n        tenor_data = ccy_data[ccy_data['tenor_bucket'] == tenor].sort_values('timestamp')\n        if not tenor_data.empty:\n            ts = tenor_data.set_index('timestamp')['nu_sqrt_T'].resample('W').median()\n            ax.plot(ts.index, ts.values, label=tenor, linewidth=1.2)\n\n    ax.set_title(f'{ccy}/USD', fontweight='bold')\n    ax.set_ylabel('Nu * sqrt(T)')\n    ax.legend(fontsize=9)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    ax.tick_params(axis='x', rotation=45)\n\nfor idx in range(len(CURRENCIES), len(axes)):\n    axes[idx].set_visible(False)\n\nfig.suptitle('SABR Nu*sqrt(T) by Currency and Tenor', fontsize=14, fontweight='bold')\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Term Structure Heatmaps\n",
    "\n",
    "Heatmap of SABR parameters across time (x-axis) and tenor (y-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from matplotlib.colors import TwoSlopeNorm\n\ndef plot_param_heatmap(param_name, title, cmap='RdYlBu_r', center=None):\n    \"\"\"Plot heatmap of a SABR parameter across currencies, time, and tenor.\"\"\"\n    ncols = 3\n    nrows = (len(CURRENCIES) + ncols - 1) // ncols\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 5 * nrows))\n    axes = axes.flatten()\n\n    for idx, ccy in enumerate(CURRENCIES):\n        ax = axes[idx]\n        ccy_data = sabr_params[sabr_params['currency'] == ccy].copy()\n        ccy_data['week'] = ccy_data['timestamp'].dt.to_period('W').dt.start_time\n\n        # Pivot: weekly median of param by tenor\n        pivot = ccy_data.pivot_table(\n            index='tenor_bucket', columns='week',\n            values=param_name, aggfunc='median'\n        )\n\n        # Reorder tenors\n        tenor_order = [t for t in ['1W', '2W', '1M', '2M', '3M', '6M', '9M', '1Y'] if t in pivot.index]\n        pivot = pivot.reindex(tenor_order)\n\n        if center is not None:\n            norm = TwoSlopeNorm(vmin=pivot.min().min(), vcenter=center, vmax=pivot.max().max())\n            im = ax.pcolormesh(pivot.columns, range(len(pivot.index)), pivot.values, cmap=cmap, norm=norm)\n        else:\n            im = ax.pcolormesh(pivot.columns, range(len(pivot.index)), pivot.values, cmap=cmap)\n\n        ax.set_yticks(range(len(pivot.index)))\n        ax.set_yticklabels(pivot.index)\n        ax.set_title(f'{ccy}/USD', fontweight='bold')\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n        ax.tick_params(axis='x', rotation=45)\n        plt.colorbar(im, ax=ax, shrink=0.8)\n\n    for idx in range(len(CURRENCIES), len(axes)):\n        axes[idx].set_visible(False)\n\n    fig.suptitle(title, fontsize=14, fontweight='bold')\n    fig.tight_layout()\n    plt.show()\n\n# Alpha heatmap\nplot_param_heatmap('alpha', 'ATM Vol (Alpha) Term Structure Over Time', cmap='YlOrRd')\n\n# Rho heatmap\nplot_param_heatmap('rho', 'Skew (Rho) Term Structure Over Time', cmap='RdBu', center=0)\n\n# Nu*sqrt(T) heatmap\nplot_param_heatmap('nu_sqrt_T', 'Nu*sqrt(T) Term Structure Over Time', cmap='viridis')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Spot vs SABR Overlay\n",
    "\n",
    "Overlays FX spot returns with SABR parameter changes to identify\n",
    "relationships between spot movements and vol surface dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spot_matrix.empty:\n",
    "    print('No spot data available. Run Section 2 with IB Gateway to collect.')\n",
    "else:\n",
    "    fig, axes = plt.subplots(len(CURRENCIES), 1, figsize=(16, 4 * len(CURRENCIES)), sharex=True)\n",
    "    if len(CURRENCIES) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, ccy in enumerate(CURRENCIES):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        # Spot price\n",
    "        if ccy in spot_matrix.columns:\n",
    "            spot = spot_matrix[ccy].dropna()\n",
    "            ax.plot(spot.index, spot.values, color='black', linewidth=1.2, label=f'{ccy}/USD Spot')\n",
    "            ax.set_ylabel(f'{ccy}/USD', color='black')\n",
    "\n",
    "        # SABR rho overlay (3M tenor)\n",
    "        ax2 = ax.twinx()\n",
    "        ccy_sabr = sabr_params[\n",
    "            (sabr_params['currency'] == ccy) & (sabr_params['tenor_bucket'] == '3M')\n",
    "        ].sort_values('timestamp')\n",
    "\n",
    "        if not ccy_sabr.empty:\n",
    "            ts = ccy_sabr.set_index('timestamp')['rho'].resample('W').median()\n",
    "            ax2.plot(ts.index, ts.values, color='red', linewidth=1.0, alpha=0.7, label='Rho (3M)')\n",
    "            ax2.set_ylabel('Rho', color='red')\n",
    "            ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "        ax.set_title(f'{ccy}/USD — Spot vs 3M Skew', fontweight='bold')\n",
    "        lines1, labels1 = ax.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=9)\n",
    "\n",
    "    axes[-1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    fig.suptitle('FX Spot vs SABR Skew (Rho, 3M)', fontsize=14, fontweight='bold')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Rolling correlation between spot returns and rho changes\nif not spot_matrix.empty:\n    ncols = 3\n    nrows = (len(CURRENCIES) + ncols - 1) // ncols\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 5 * nrows), sharex=True)\n    axes = axes.flatten()\n\n    for idx, ccy in enumerate(CURRENCIES):\n        ax = axes[idx]\n\n        if ccy not in spot_matrix.columns:\n            ax.set_title(f'{ccy}/USD — no spot data')\n            continue\n\n        spot_ret = spot_matrix[ccy].pct_change()\n\n        for tenor in ['1M', '3M', '6M']:\n            ccy_sabr = sabr_params[\n                (sabr_params['currency'] == ccy) & (sabr_params['tenor_bucket'] == tenor)\n            ].sort_values('timestamp')\n\n            if ccy_sabr.empty:\n                continue\n\n            # Daily rho change\n            rho_ts = ccy_sabr.set_index('timestamp')['rho'].resample('B').last().dropna()\n            rho_change = rho_ts.diff()\n\n            # Align\n            aligned = pd.DataFrame({'spot_ret': spot_ret, 'rho_change': rho_change}).dropna()\n            if len(aligned) > 63:\n                corr = aligned['spot_ret'].rolling(63).corr(aligned['rho_change'])\n                ax.plot(corr.index, corr.values, label=tenor, linewidth=1.0)\n\n        ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8)\n        ax.set_title(f'{ccy}/USD', fontweight='bold')\n        ax.set_ylabel('Rolling 63d Corr')\n        ax.set_ylim(-1, 1)\n        ax.legend(fontsize=9)\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n        ax.tick_params(axis='x', rotation=45)\n\n    for idx in range(len(CURRENCIES), len(axes)):\n        axes[idx].set_visible(False)\n\n    fig.suptitle('Rolling Correlation: Spot Returns vs Rho Change', fontsize=14, fontweight='bold')\n    fig.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Summary:** This notebook provides a comprehensive view of FX volatility surface dynamics.\n",
    "Key outputs for further analysis:\n",
    "\n",
    "- `~/trade_data/ETFTrader/fx_sabr/sabr_params_historical.parquet` — Full SABR parameter history\n",
    "- The SABR parameters (alpha, rho, nu) can be used as features for FX trading signals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}