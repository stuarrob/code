{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# FX Skew Divergence Signal Investigation — GBP Focus\n\n**Key finding from v1:** When a short-dated tenor moves but a longer tenor *hasn't yet moved*,\nGBPUSD spot moves in the direction implied by the short tenor. The edge disappears once the long tenor catches up.\n\n**v2 finding:** 1M vs 3M divergence works (t=5.98 at best). \n**v3 question:** Can 1W options detect the move even *earlier* than 1M?\n\n**Signal concept:** `divergence = (fast tenor rho moved) AND (slow tenor rho still quiet)`\n\n**Tenor pairs tested:**\n- **1W -> 1M** (1W moved, 1M hasn't yet — earliest possible entry)\n- **1W -> 3M** (1W moved, 3M hasn't yet — maximum divergence)\n- **1M -> 3M** (1M moved, 3M hasn't yet — the v2 baseline)\n\n| Section | Content |\n|---------|--------|\n| 0 | Setup & Configuration |\n| 1 | Load & Prepare GBP Data |\n| 2 | Reproduce Key Finding — Cascade Timing |\n| 3 | Build Divergence Signal Engine |\n| 4 | Divergence Signal Evaluation — Grid Search |\n| 5 | Ablation: Divergence vs Fast-Only vs Slow-Quiet |\n| 6 | Optimal MA Window Deep-Dive |\n| 7 | Event Study — Divergence Events |\n| 8 | Signal Magnitude — Does Size Matter? |\n| 9 | Alpha & Nu Confirmation |\n| 10 | Backtest — Best Divergence Signal |\n| 11 | Robustness & Reality Check |\n| 12 | Summary & Next Steps |"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 0: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "import warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom scipy import stats\n\nwarnings.filterwarnings('ignore')\npd.set_option('future.no_silent_downcasting', True)\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams.update({'figure.figsize': (14, 6), 'font.size': 11})\n\nDATA_DIR = Path.home() / 'trade_data' / 'ETFTrader'\nFX_SPOT_DIR = DATA_DIR / 'fx_spot'\nFX_SABR_DIR = DATA_DIR / 'fx_sabr'\n\n# Focus currency\nCCY = 'GBP'\nPAIR = 'GBPUSD'\n\n# Tenors — now includes 1W for earlier detection\nTENORS = ['1W', '1M', '3M', '6M']\nTARGET_DTE = {'1W': 7, '1M': 30, '3M': 91, '6M': 182}\n\n# Tenor pairs: (fast, slow) — fast moves first, slow should be quiet\nTENOR_PAIRS = [\n    ('1W', '1M'),   # 1W moved, 1M hasn't yet (earliest entry)\n    ('1W', '3M'),   # 1W moved, 3M hasn't yet (max divergence)\n    ('1M', '3M'),   # 1M moved, 3M hasn't yet (v2 baseline)\n]\n\n# MA windows to test for divergence detection\nMA_WINDOWS = [3, 5, 7, 10, 14, 21]\n\n# Forward return horizons\nHORIZONS = {'1d': 1, '5d': 5, '10d': 10, '21d': 21}\n\n# Rho boundary filter\nRHO_BOUNDARY = 0.98\n\nRANDOM_STATE = 42\nCOLORS_TENOR = {'1W': '#9b59b6', '1M': '#e74c3c', '3M': '#3498db', '6M': '#2ecc71'}\nCOLORS_PAIR = {'1W1M': '#9b59b6', '1W3M': '#e67e22', '1M3M': '#3498db'}\n\nprint(f'Currency: {CCY} ({PAIR})')\nprint(f'Tenors:   {TENORS}')\nprint(f'Tenor pairs: {[f\"{f}->{s}\" for f, s in TENOR_PAIRS]}')\nprint(f'MA windows to test: {MA_WINDOWS}')\nprint(f'Horizons: {list(HORIZONS.keys())}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Load & Prepare GBP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and clean SABR params ---\n",
    "sabr_raw = pd.read_parquet(FX_SABR_DIR / 'sabr_params_historical.parquet')\n",
    "sabr_raw['date'] = pd.to_datetime(sabr_raw['timestamp']).dt.normalize()\n",
    "\n",
    "sabr = sabr_raw[(sabr_raw['currency'] == CCY) & (sabr_raw['tenor_bucket'].isin(TENORS))].copy()\n",
    "print(f'GBP SABR rows (raw): {len(sabr)}')\n",
    "\n",
    "# Remove boundary rho (calibration failures)\n",
    "boundary_mask = sabr['rho'].abs() > RHO_BOUNDARY\n",
    "print(f'Boundary rho removed: {boundary_mask.sum()} ({boundary_mask.mean():.1%})')\n",
    "sabr = sabr[~boundary_mask].copy()\n",
    "\n",
    "# Deduplicate: keep row closest to target DTE per (date, tenor)\n",
    "sabr['target_dte'] = sabr['tenor_bucket'].map(TARGET_DTE)\n",
    "sabr['dte_diff'] = (sabr['dte'] - sabr['target_dte']).abs()\n",
    "sabr = sabr.sort_values('dte_diff').drop_duplicates(['date', 'tenor_bucket'], keep='first')\n",
    "sabr = sabr.drop(columns=['target_dte', 'dte_diff'])\n",
    "\n",
    "# Pivot wide\n",
    "df = sabr.pivot_table(index='date', columns='tenor_bucket',\n",
    "                      values=['rho', 'alpha', 'nu'], aggfunc='first')\n",
    "df.columns = [f'{p}_{t}' for p, t in df.columns]\n",
    "df = df.reset_index().sort_values('date')\n",
    "\n",
    "print(f'\\nPivoted: {len(df)} dates')\n",
    "for t in TENORS:\n",
    "    col = f'rho_{t}'\n",
    "    if col in df.columns:\n",
    "        print(f'  {t}: {df[col].notna().sum()} dates with rho')\n",
    "\n",
    "has_1M_3M = df['rho_1M'].notna() & df['rho_3M'].notna()\n",
    "print(f'\\n  Both 1M+3M: {has_1M_3M.sum()} dates (primary analysis set)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# --- Load GBPUSD spot and compute forward returns ---\nspot_raw = pd.read_parquet(FX_SPOT_DIR / f'{PAIR}.parquet')\nspot_raw['date'] = pd.to_datetime(spot_raw['date']).dt.normalize()\nspot_raw = spot_raw.sort_values('date')\n\nfor label, days in HORIZONS.items():\n    spot_raw[f'fwd_ret_{label}'] = spot_raw['close'].shift(-days) / spot_raw['close'] - 1\n\n# Merge\nmerge_cols = ['date', 'close'] + [c for c in spot_raw.columns if c.startswith('fwd_')]\ndf = df.merge(spot_raw[merge_cols], on='date', how='left')\ndf = df.rename(columns={'close': 'spot'})\n\nprint(f'Merged: {len(df)} rows, spot coverage: {df[\"spot\"].notna().sum()}')\nprint(f'Date range: {df[\"date\"].min().date()} to {df[\"date\"].max().date()}')\n\n# --- Per-pair data masks ---\nmask_pair = {}\nfor fast, slow in TENOR_PAIRS:\n    m = df[f'rho_{fast}'].notna() & df[f'rho_{slow}'].notna()\n    pair_label = f'{fast}{slow}'\n    mask_pair[(fast, slow)] = m\n    print(f'  {fast}->{slow} overlap: {m.sum()} dates')\n\n# Legacy alias for downstream code\nhas_1M_3M = mask_pair.get(('1M', '3M'), df['rho_1M'].notna() & df['rho_3M'].notna())\n\n# Quick look\nsample_cols = ['date', 'spot', 'rho_1W', 'rho_1M', 'rho_3M', 'fwd_ret_5d']\navail = [c for c in sample_cols if c in df.columns]\nprint(f'\\nLast 5 rows with 1W+1M+3M:')\nmask_all3 = df['rho_1M'].notna() & df['rho_3M'].notna()\nif 'rho_1W' in df.columns:\n    mask_all3 = mask_all3 & df['rho_1W'].notna()\nprint(df.loc[mask_all3, avail].tail().to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Reproduce the Key Finding — Cascade Timing\n",
    "\n",
    "v1 of this notebook tested cascades (1M steepens/flattens → 3M follows). The striking result:\n",
    "**the edge exists at the 1M trigger and vanishes by the time 3M confirms.**\n",
    "This section reproduces that finding to motivate the divergence approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# 2a. Detect cascades across tenor pairs\n# Compute 5d rho changes for all tenors\nfor tenor in TENORS:\n    col = f'rho_{tenor}'\n    if col in df.columns:\n        df[f'{col}_chg5d'] = df[col].diff(5)\n\n# Steepening/flattening thresholds (p25) for each tenor\nthresholds = {}\nfor tenor in ['1W', '1M', '3M']:\n    chg_col = f'rho_{tenor}_chg5d'\n    if chg_col not in df.columns:\n        continue\n    chg = df[chg_col].dropna()\n    if len(chg) < 20:\n        continue\n    thresholds[tenor] = {'p25': chg.quantile(0.25), 'p75': chg.quantile(0.75)}\n    print(f'rho_{tenor} 5d change: p25={thresholds[tenor][\"p25\"]:.4f}, p75={thresholds[tenor][\"p75\"]:.4f}')\n\n# Mark threshold-crossing events\nfor tenor in thresholds:\n    chg_col = f'rho_{tenor}_chg5d'\n    df[f'steep_{tenor}'] = (df[chg_col] < thresholds[tenor]['p25']).astype(float)\n    df.loc[df[chg_col].isna(), f'steep_{tenor}'] = np.nan\n    df[f'flat_{tenor}'] = (df[chg_col] > thresholds[tenor]['p75']).astype(float)\n    df.loc[df[chg_col].isna(), f'flat_{tenor}'] = np.nan\n\n# Cascade detection function (parameterised by trigger/confirm tenor)\ndef detect_cascades(df, direction, trigger_tenor='1M', confirm_tenor='3M', max_lag=10):\n    \"\"\"Detect fast->slow cascades. direction='steep' or 'flat'.\"\"\"\n    sig_t = f'{direction}_{trigger_tenor}'\n    sig_c = f'{direction}_{confirm_tenor}'\n    if sig_t not in df.columns or sig_c not in df.columns:\n        return []\n    cascades = []\n    used = set()\n    for i in range(len(df)):\n        if df[sig_t].iloc[i] != 1.0 or df['date'].iloc[i] in used:\n            continue\n        for j in range(i + 1, min(i + max_lag + 1, len(df))):\n            if df[sig_c].iloc[j] == 1.0:\n                cascades.append({'idx_trigger': i, 'idx_confirm': j,\n                                 'lag': j - i, 'date_trigger': df['date'].iloc[i]})\n                used.add(df['date'].iloc[i])\n                break\n    return cascades\n\n# Detect cascades for each tenor pair\nall_cascades = {}\nfor fast, slow in TENOR_PAIRS:\n    for direction, label in [('steep', 'bearish'), ('flat', 'bullish')]:\n        key = (fast, slow, direction)\n        c = detect_cascades(df, direction, trigger_tenor=fast, confirm_tenor=slow)\n        all_cascades[key] = c\n        if c:\n            print(f'{label.title()} cascade {fast}->{slow}: {len(c)} events')\n\n# Legacy references for the 1M->3M pair\ncascades_steep = all_cascades.get(('1M', '3M', 'steep'), [])\ncascades_flat = all_cascades.get(('1M', '3M', 'flat'), [])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# 2b. THE KEY RESULT: returns at trigger vs at confirmation — now for ALL pairs\nprint('=== CASCADE TIMING: Edge at Trigger vs at Confirmation ===\\n')\nprint(f'{\"Pair\":<8s} {\"Signal\":<18s} {\"Entry\":<18s} {\"Horizon\":<8s} '\n      f'{\"Mean ret\":>10s} {\"t\":>7s} {\"p\":>7s} {\"Hit%\":>6s} {\"n\":>4s}')\nprint('-' * 105)\n\nfor fast, slow in TENOR_PAIRS:\n    for label, direction, sign in [('Bearish', 'steep', -1), ('Bullish', 'flat', +1)]:\n        cascades = all_cascades.get((fast, slow, direction), [])\n        if not cascades:\n            continue\n        pair_str = f'{fast}->{slow}'\n        for entry, idx_key in [(f'At {fast} trigger', 'idx_trigger'),\n                                (f'At {slow} confirm', 'idx_confirm')]:\n            for h_label in ['5d', '10d']:\n                ret_col = f'fwd_ret_{h_label}'\n                rets = []\n                for c in cascades:\n                    idx = c[idx_key]\n                    if idx < len(df) and pd.notna(df[ret_col].iloc[idx]):\n                        rets.append(df[ret_col].iloc[idx] * sign)\n                if len(rets) > 3:\n                    rets = np.array(rets)\n                    t, p = stats.ttest_1samp(rets, 0)\n                    hit = np.mean(rets > 0)\n                    print(f'{pair_str:<8s} {label:<18s} {entry:<18s} {h_label:<8s} '\n                          f'{rets.mean()*10000:>+9.1f}bps {t:>7.2f} {p:>7.3f} '\n                          f'{hit:>5.0%} {len(rets):>4d}')\n\nprint('\\n>>> Compare: does 1W trigger capture the edge EARLIER than 1M trigger?')\nprint('>>> Key: look for strong t-stats at \"trigger\" that vanish at \"confirm\".')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "# 2c. Visual: event study overlay — now includes 1W trigger where available\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\nevent_window = 21\n\nfor ax, (label, direction, cascade_sign) in zip(axes,\n        [('Bullish cascade (fast flattens)', 'flat', +1),\n         ('Bearish cascade (fast steepens)', 'steep', -1)]):\n\n    # Plot each tenor pair's trigger timing\n    for fast, slow in TENOR_PAIRS:\n        pair_label = f'{fast}{slow}'\n        color = COLORS_PAIR.get(pair_label, 'black')\n        cascades = all_cascades.get((fast, slow, direction), [])\n        if not cascades:\n            continue\n        # At trigger\n        paths = []\n        for c in cascades:\n            idx = c['idx_trigger']\n            if idx + event_window < len(df):\n                fwd = df['spot'].iloc[idx:idx + event_window + 1].values\n                if not np.any(np.isnan(fwd)):\n                    paths.append((fwd / fwd[0] - 1) * 100 * cascade_sign)\n        if paths:\n            paths = np.array(paths)\n            avg = paths.mean(axis=0)\n            sem = paths.std(axis=0) / np.sqrt(len(paths))\n            days = range(event_window + 1)\n            ax.plot(days, avg, color=color, linewidth=2, linestyle='-',\n                    label=f'@ {fast} trigger (n={len(paths)})')\n            ax.fill_between(days, avg - 1.96*sem, avg + 1.96*sem,\n                            alpha=0.08, color=color)\n\n    # Also plot 3M confirm for 1M->3M as dashed reference\n    cascades_ref = all_cascades.get(('1M', '3M', direction), [])\n    if cascades_ref:\n        paths = []\n        for c in cascades_ref:\n            idx = c['idx_confirm']\n            if idx + event_window < len(df):\n                fwd = df['spot'].iloc[idx:idx + event_window + 1].values\n                if not np.any(np.isnan(fwd)):\n                    paths.append((fwd / fwd[0] - 1) * 100 * cascade_sign)\n        if paths:\n            paths = np.array(paths)\n            avg = paths.mean(axis=0)\n            days = range(event_window + 1)\n            ax.plot(days, avg, color='gray', linewidth=1.5, linestyle='--',\n                    label=f'@ 3M confirm (n={len(paths)})')\n\n    ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n    ax.set_xlabel('Days after entry')\n    ax.set_ylabel('Cumulative signed GBPUSD return (%)')\n    ax.set_title(label, fontweight='bold')\n    ax.legend(fontsize=8)\n\nfig.suptitle('Cascade Event Study: 1W vs 1M Trigger vs 3M Confirmation\\n'\n             'Earlier trigger = more edge captured?',\n             fontweight='bold')\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": "---\n## Section 3: Build the Divergence Signal Engine\n\n**Divergence = (fast tenor rho moved significantly) AND (slow tenor rho still quiet)**\n\nTest across three tenor pairs: 1W->1M, 1W->3M, 1M->3M.\nMultiple detection methods and MA windows to find the optimal timing."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "# 3a. Multi-window detection metrics for ALL tenors used in pairs\n# For each window N, compute:\n#   - deviation from MA: rho - rho.rolling(N).mean()\n#   - simple change: rho - rho.shift(N)\n#   - MA crossover: fast MA - slow MA (for N >= 5)\n\n# Collect all tenors that appear in any pair\npair_tenors = sorted(set(t for pair in TENOR_PAIRS for t in pair))\n\ndetection_cols = {}  # (tenor, method, window) -> column name\n\nfor tenor in pair_tenors:\n    rho_col = f'rho_{tenor}'\n    if rho_col not in df.columns:\n        continue\n\n    for N in MA_WINDOWS:\n        # Deviation from MA\n        col_dev = f'rho_{tenor}_dev{N}d'\n        if col_dev not in df.columns:\n            df[col_dev] = df[rho_col] - df[rho_col].rolling(N, min_periods=max(2, N//2)).mean()\n        detection_cols[(tenor, 'dev', N)] = col_dev\n\n        # Simple change\n        col_chg = f'rho_{tenor}_chg{N}d'\n        if col_chg not in df.columns:\n            df[col_chg] = df[rho_col] - df[rho_col].shift(N)\n        detection_cols[(tenor, 'chg', N)] = col_chg\n\n        # MA crossover (fast=min(3,N) vs slow=N, only if N >= 5)\n        if N >= 5:\n            fast_w = min(3, N // 2)\n            col_cross = f'rho_{tenor}_cross{N}d'\n            if col_cross not in df.columns:\n                df[col_cross] = (df[rho_col].rolling(fast_w, min_periods=2).mean()\n                                 - df[rho_col].rolling(N, min_periods=max(3, N//2)).mean())\n            detection_cols[(tenor, 'cross', N)] = col_cross\n\nprint(f'Detection metrics computed: {len(detection_cols)} columns')\nfor tenor in pair_tenors:\n    n = sum(1 for k in detection_cols if k[0] == tenor)\n    print(f'  {tenor} metrics: {n}')\n\n# Show distributions for key metrics per tenor\nprint(f'\\nKey detection metric distributions:')\nfor tenor in pair_tenors:\n    mask_t = df[f'rho_{tenor}'].notna()\n    for method in ['dev', 'chg']:\n        for N in [3, 5, 7]:\n            key = (tenor, method, N)\n            if key in detection_cols:\n                col = detection_cols[key]\n                vals = df.loc[mask_t, col].dropna()\n                if len(vals) > 10:\n                    print(f'  {col}: p10={vals.quantile(0.1):.4f}, p25={vals.quantile(0.25):.4f}, '\n                          f'p75={vals.quantile(0.75):.4f}, p90={vals.quantile(0.9):.4f} (n={len(vals)})')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# 3b. \"Slow tenor quiet\" condition\n# For each slow tenor in our pairs, compute quiet thresholds\n# \"Quiet\" = |slow tenor change| is below median or p25 of absolute changes\n\n# Identify all slow tenors from TENOR_PAIRS\nslow_tenors = sorted(set(slow for _, slow in TENOR_PAIRS))\n\nquiet_thresholds = {}  # (slow_tenor, method, window, level) -> threshold value\n\nfor slow_tenor in slow_tenors:\n    print(f'{slow_tenor} \"quiet\" thresholds (absolute change below this = quiet):\\n')\n    for method in ['dev', 'chg']:\n        for N in MA_WINDOWS:\n            key = (slow_tenor, method, N)\n            if key not in detection_cols:\n                continue\n            col = detection_cols[key]\n            # Use dates where slow tenor has data\n            vals = df.loc[df[f'rho_{slow_tenor}'].notna(), col].dropna().abs()\n            if len(vals) < 20:\n                continue\n            for level, q in [('med', 0.5), ('q25', 0.25)]:\n                thresh = vals.quantile(q)\n                quiet_thresholds[(slow_tenor, method, N, level)] = thresh\n            print(f'  |rho_{slow_tenor}_{method}{N}d|: median={vals.quantile(0.5):.4f}, '\n                  f'p25={vals.quantile(0.25):.4f} (n={len(vals)})')\n    print()\n\nprint(f'Total quiet thresholds: {len(quiet_thresholds)}')\nfor st in slow_tenors:\n    n = sum(1 for k in quiet_thresholds if k[0] == st)\n    print(f'  {st}: {n} thresholds')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "# 3c. Compose divergence signals for ALL tenor pairs\n# divergence = (fast tenor metric exceeds threshold) AND (slow tenor is quiet)\n\ndivergence_signals = {}  # name -> (mask, expected_sign)\n\nfor fast_tenor, slow_tenor in TENOR_PAIRS:\n    pair_label = f'{fast_tenor}{slow_tenor}'\n    pair_mask = mask_pair[(fast_tenor, slow_tenor)]\n    n_pair_dates = pair_mask.sum()\n\n    if n_pair_dates < 30:\n        print(f'Skipping {pair_label}: only {n_pair_dates} overlap dates')\n        continue\n\n    for method_fast in ['dev', 'chg', 'cross']:\n        for win_fast in MA_WINDOWS:\n            key_fast = (fast_tenor, method_fast, win_fast)\n            if key_fast not in detection_cols:\n                continue\n            col_fast = detection_cols[key_fast]\n            vals_fast = df.loc[pair_mask, col_fast].dropna()\n            if len(vals_fast) < 30:\n                continue\n\n            for q_label, q in [('p25', 0.25), ('p10', 0.10)]:\n                thresh_lo = vals_fast.quantile(q)       # bearish: fast drops below this\n                thresh_hi = vals_fast.quantile(1 - q)   # bullish: fast rises above this\n\n                # --- Divergence signals (with slow-tenor quiet filter) ---\n                for method_slow in ['dev', 'chg']:\n                    for win_slow in MA_WINDOWS:\n                        key_slow = (slow_tenor, method_slow, win_slow)\n                        if key_slow not in detection_cols:\n                            continue\n                        col_slow = detection_cols[key_slow]\n\n                        for quiet_level in ['med', 'q25']:\n                            qt_key = (slow_tenor, method_slow, win_slow, quiet_level)\n                            if qt_key not in quiet_thresholds:\n                                continue\n                            qt = quiet_thresholds[qt_key]\n                            quiet_mask = df[col_slow].abs() < qt\n\n                            # Bearish divergence: fast drops, slow quiet\n                            name_bear = (f'bear_div_{pair_label}_{method_fast}{win_fast}d'\n                                         f'_{q_label}_{method_slow}{win_slow}d_{quiet_level}')\n                            mask_bear = (df[col_fast] < thresh_lo) & quiet_mask & pair_mask\n                            if mask_bear.sum() >= 5:\n                                divergence_signals[name_bear] = (mask_bear, -1)\n\n                            # Bullish divergence: fast rises, slow quiet\n                            name_bull = (f'bull_div_{pair_label}_{method_fast}{win_fast}d'\n                                         f'_{q_label}_{method_slow}{win_slow}d_{quiet_level}')\n                            mask_bull = (df[col_fast] > thresh_hi) & quiet_mask & pair_mask\n                            if mask_bull.sum() >= 5:\n                                divergence_signals[name_bull] = (mask_bull, +1)\n\n                # --- Fast-tenor-only signals (for ablation) ---\n                name_fast_bear = f'bear_{fast_tenor}only_{method_fast}{win_fast}d_{q_label}'\n                mask_fast_bear = (df[col_fast] < thresh_lo) & pair_mask\n                if mask_fast_bear.sum() >= 5 and name_fast_bear not in divergence_signals:\n                    divergence_signals[name_fast_bear] = (mask_fast_bear, -1)\n\n                name_fast_bull = f'bull_{fast_tenor}only_{method_fast}{win_fast}d_{q_label}'\n                mask_fast_bull = (df[col_fast] > thresh_hi) & pair_mask\n                if mask_fast_bull.sum() >= 5 and name_fast_bull not in divergence_signals:\n                    divergence_signals[name_fast_bull] = (mask_fast_bull, +1)\n\n# Summary\nn_div = sum(1 for k in divergence_signals if '_div_' in k)\nn_only = sum(1 for k in divergence_signals if 'only' in k.lower())\nprint(f'Total signals: {len(divergence_signals)}')\nprint(f'  Divergence: {n_div}')\nprint(f'  Fast-only (ablation): {n_only}')\n\n# Breakdown by pair\nfor fast, slow in TENOR_PAIRS:\n    pair_label = f'{fast}{slow}'\n    n_pair = sum(1 for k in divergence_signals if f'_div_{pair_label}_' in k)\n    print(f'  {fast}->{slow} divergence: {n_pair}')\nn_1w = sum(1 for k in divergence_signals if '1Wonly' in k)\nn_1m = sum(1 for k in divergence_signals if '1Monly' in k)\nprint(f'  1W-only: {n_1w}, 1M-only: {n_1m}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Divergence Signal Evaluation — Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# 4a. Evaluate all signals\ndef evaluate_signals(signal_dict, df, horizons=('5d', '10d')):\n    \"\"\"Evaluate all signals: mean signed return, t-stat, p-value, hit rate.\"\"\"\n    results = []\n    for name, (mask, expected_sign) in signal_dict.items():\n        mask_clean = mask.fillna(False).astype(bool)\n        events = df.index[mask_clean]\n        for h in horizons:\n            ret_col = f'fwd_ret_{h}'\n            rets = df.loc[events, ret_col].dropna()\n            if len(rets) < 5:\n                continue\n            signed = rets * expected_sign\n            t, p = stats.ttest_1samp(signed, 0)\n            # Extract tenor pair from signal name\n            pair = 'unknown'\n            for fast, slow in TENOR_PAIRS:\n                pl = f'{fast}{slow}'\n                if f'_div_{pl}_' in name:\n                    pair = f'{fast}->{slow}'\n                    break\n            if 'only' in name.lower():\n                pair = name.split('_')[1].replace('only', '-only')  # e.g. '1W-only'\n            results.append({\n                'signal': name, 'horizon': h,\n                'direction': 'bear' if expected_sign == -1 else 'bull',\n                'pair': pair,\n                'n': len(rets),\n                'mean_bps': signed.mean() * 10000,\n                'hit_rate': (signed > 0).mean(),\n                't_stat': t, 'p_value': p,\n            })\n    res = pd.DataFrame(results).sort_values('t_stat', ascending=False)\n    n_tests = len(res)\n    res['p_bonf'] = (res['p_value'] * n_tests).clip(upper=1.0)\n    res['sig_bonf'] = res['p_bonf'] < 0.05\n    return res\n\nresults_df = evaluate_signals(divergence_signals, df)\n\nn_tests = len(results_df)\nn_sig = (results_df['p_value'] < 0.05).sum()\nn_bonf = results_df['sig_bonf'].sum()\n\nprint(f'=== GRID SEARCH: {n_tests} tests ===')\nprint(f'Significant at p<0.05 (raw):  {n_sig}')\nprint(f'Significant after Bonferroni: {n_bonf}')\nprint(f'Expected false positives:     {n_tests * 0.05:.1f}')\n\n# Separate divergence vs fast-only results\ndiv_results = results_df[results_df['signal'].str.contains('_div_')]\nonly_results = results_df[results_df['signal'].str.contains('only')]\n\n# Breakdown by pair\nprint(f'\\n--- By tenor pair ---')\nfor fast, slow in TENOR_PAIRS:\n    pair_label = f'{fast}{slow}'\n    pair_div = div_results[div_results['signal'].str.contains(f'_div_{pair_label}_')]\n    n_sig_pair = (pair_div['p_value'] < 0.05).sum()\n    print(f'  {fast}->{slow}: {len(pair_div)} tests, p<0.05: {n_sig_pair}')\n\nprint(f'\\n--- Fast-only signals ---')\nfor tenor in sorted(set(f for f, _ in TENOR_PAIRS)):\n    t_only = only_results[only_results['signal'].str.contains(f'{tenor}only')]\n    n_sig_t = (t_only['p_value'] < 0.05).sum()\n    print(f'  {tenor}-only: {len(t_only)} tests, p<0.05: {n_sig_t}')\n\nprint(f'\\nTop 15 divergence signals by t-stat:\\n')\ncols = ['signal', 'pair', 'horizon', 'n', 'mean_bps', 'hit_rate', 't_stat', 'p_value', 'sig_bonf']\nprint(div_results[cols].head(15).to_string(index=False, float_format='%.3f'))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "# 4b. Heatmap: best t-stat by tenor pair x detection method x window\n\ndef parse_signal_name(name):\n    \"\"\"Extract components from the generalised signal name.\"\"\"\n    parts = {}\n    parts['is_div'] = '_div_' in name\n    parts['direction'] = 'bear' if name.startswith('bear') else 'bull'\n    if parts['is_div']:\n        after_div = name.split('_div_')[1]\n        # First token is pair label (e.g., '1W1M', '1M3M')\n        tokens = after_div.split('_')\n        parts['pair'] = tokens[0]\n        # Find the fast tenor pair\n        for ft, st in TENOR_PAIRS:\n            if tokens[0] == f'{ft}{st}':\n                parts['fast_tenor'] = ft\n                parts['slow_tenor'] = st\n                break\n        # tokens[1] = method+window (e.g., 'chg3d')\n        mw = tokens[1]\n        for m in ['cross', 'dev', 'chg']:\n            if mw.startswith(m):\n                parts['method_fast'] = m\n                parts['win_fast'] = int(mw[len(m):-1])\n                break\n        parts['threshold'] = tokens[2]  # 'p25' or 'p10'\n        # tokens[3] = slow method+window (e.g., 'dev5d')\n        sm = tokens[3]\n        for m in ['cross', 'dev', 'chg']:\n            if sm.startswith(m):\n                parts['method_slow'] = m\n                parts['win_slow'] = int(sm[len(m):-1])\n                break\n        parts['quiet_level'] = tokens[4] if len(tokens) > 4 else 'med'\n    else:\n        # Fast-only signal: e.g., 'bull_1Wonly_chg3d_p25'\n        after = name.split('only_')[1] if 'only_' in name else ''\n        tokens = after.split('_')\n        mw = tokens[0]\n        for m in ['cross', 'dev', 'chg']:\n            if mw.startswith(m):\n                parts['method_fast'] = m\n                parts['win_fast'] = int(mw[len(m):-1])\n                break\n        parts['threshold'] = tokens[1] if len(tokens) > 1 else 'p25'\n        # Extract tenor\n        for tenor in ['1W', '1M', '3M']:\n            if f'{tenor}only' in name:\n                parts['fast_tenor'] = tenor\n                break\n    return parts\n\n# Per-pair heatmap: method x window -> best t-stat\nn_pairs = len(TENOR_PAIRS)\nfig, axes = plt.subplots(1, n_pairs, figsize=(6 * n_pairs, 5))\nif n_pairs == 1:\n    axes = [axes]\nmethods = ['dev', 'chg', 'cross']\nwindows = MA_WINDOWS\n\nfor ax, (fast, slow) in zip(axes, TENOR_PAIRS):\n    pair_label = f'{fast}{slow}'\n    pair_div = div_results[(div_results['signal'].str.contains(f'_div_{pair_label}_')) &\n                           (div_results['horizon'] == '5d')]\n\n    grid = np.full((len(methods), len(windows)), np.nan)\n    for _, row in pair_div.iterrows():\n        try:\n            p = parse_signal_name(row['signal'])\n        except (ValueError, IndexError, KeyError):\n            continue\n        m_idx = methods.index(p['method_fast']) if p.get('method_fast') in methods else -1\n        w_idx = windows.index(p['win_fast']) if p.get('win_fast') in windows else -1\n        if m_idx >= 0 and w_idx >= 0:\n            if np.isnan(grid[m_idx, w_idx]) or row['t_stat'] > grid[m_idx, w_idx]:\n                grid[m_idx, w_idx] = row['t_stat']\n\n    im = ax.imshow(grid, cmap='RdYlGn', aspect='auto', vmin=-2, vmax=4)\n    ax.set_xticks(range(len(windows)))\n    ax.set_xticklabels([f'{w}d' for w in windows])\n    ax.set_yticks(range(len(methods)))\n    ax.set_yticklabels(['Deviation', 'Change', 'MA Cross'])\n    ax.set_xlabel(f'{fast} Detection Window')\n    ax.set_title(f'{fast}->{slow} divergence\\n(best t-stat, 5d horizon)',\n                 fontweight='bold', color=COLORS_PAIR.get(pair_label, 'black'))\n    for i in range(len(methods)):\n        for j in range(len(windows)):\n            if not np.isnan(grid[i, j]):\n                ax.text(j, i, f'{grid[i,j]:.1f}', ha='center', va='center',\n                        fontsize=9, fontweight='bold' if grid[i,j] > 1.96 else 'normal')\n\nplt.colorbar(im, ax=axes, shrink=0.8, label='t-statistic')\nfig.suptitle('Divergence Signal t-stats by Tenor Pair, Method, and Window', fontweight='bold')\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "# 4c. Top 20 overall — with tenor pair annotation\nprint('=== TOP 20 SIGNALS (ALL TYPES) ===\\n')\ncols = ['signal', 'pair', 'horizon', 'n', 'mean_bps', 'hit_rate', 't_stat', 'p_value', 'sig_bonf']\ntop20 = results_df[cols].head(20)\nprint(top20.to_string(index=False, float_format='%.3f'))\n\n# Count by type in top 20\nprint(f'\\n--- Top 20 breakdown ---')\nfor fast, slow in TENOR_PAIRS:\n    pair_label = f'{fast}{slow}'\n    n = sum(f'_div_{pair_label}_' in s for s in top20['signal'])\n    if n > 0:\n        print(f'  {fast}->{slow} divergence: {n}')\nn_only_top = sum('only' in s for s in top20['signal'])\nif n_only_top > 0:\n    print(f'  Fast-only: {n_only_top}')\n\n# KEY COMPARISON: best signal per pair\nprint(f'\\n=== BEST SIGNAL PER TENOR PAIR (5d horizon) ===\\n')\ndiv_5d = div_results[div_results['horizon'] == '5d']\nfor fast, slow in TENOR_PAIRS:\n    pair_label = f'{fast}{slow}'\n    pair_best = div_5d[div_5d['signal'].str.contains(f'_div_{pair_label}_')]\n    if len(pair_best) > 0:\n        row = pair_best.iloc[0]\n        print(f'  {fast}->{slow}: t={row[\"t_stat\"]:.2f}, hit={row[\"hit_rate\"]:.0%}, '\n              f'n={row[\"n\"]}, edge={row[\"mean_bps\"]:+.1f}bps')\n        print(f'     {row[\"signal\"]}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": "---\n## Section 5: Ablation — Does the \"Slow Quiet\" Filter Help?\n\nThe critical test: compare each divergence signal to its fast-tenor-only counterpart.\nIf divergence > fast-only, the slow quiet filter genuinely adds value.\nTest this separately for each tenor pair (1W->1M, 1W->3M, 1M->3M)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "# 5a. Paired comparison: divergence vs fast-only for each tenor pair\nablation_pairs = []\n\nonly_5d = only_results[only_results['horizon'] == '5d'].copy()\ndiv_5d = div_results[div_results['horizon'] == '5d'].copy()\n\nfor _, row_only in only_5d.iterrows():\n    name_only = row_only['signal']\n    # Extract the fast tenor and method/window from the only-signal name\n    # e.g., 'bear_1Wonly_chg3d_p25' -> look for 'bear_div_1W??_chg3d_p25_*'\n    for fast_tenor in ['1W', '1M']:\n        if f'{fast_tenor}only' not in name_only:\n            continue\n        # The method+window+threshold part after 'only_'\n        suffix = name_only.split('only_')[1]  # e.g., 'chg3d_p25'\n\n        # Find matching divergence signals for this fast tenor across all slow tenors\n        for _, slow_tenor in [(f, s) for f, s in TENOR_PAIRS if f == fast_tenor]:\n            pair_label = f'{fast_tenor}{slow_tenor}'\n            prefix = f'{row_only[\"direction\"]}_div_{pair_label}_{suffix}'\n            matching = div_5d[div_5d['signal'].str.startswith(prefix)]\n            if len(matching) > 0:\n                best_div = matching.sort_values('t_stat', ascending=False).iloc[0]\n                ablation_pairs.append({\n                    'fast_signal': name_only,\n                    'div_signal': best_div['signal'],\n                    'pair': f'{fast_tenor}->{slow_tenor}',\n                    't_fast': row_only['t_stat'],\n                    't_div': best_div['t_stat'],\n                    'delta_t': best_div['t_stat'] - row_only['t_stat'],\n                    'n_fast': row_only['n'],\n                    'n_div': best_div['n'],\n                    'hit_div': best_div['hit_rate'],\n                })\n\nabl_df = pd.DataFrame(ablation_pairs).sort_values('delta_t', ascending=False)\n\nprint('=== ABLATION: Divergence vs Fast-Only ===\\n')\nprint(f'Cases where divergence improves on fast-only: '\n      f'{(abl_df[\"delta_t\"] > 0).sum()} / {len(abl_df)}')\nprint(f'Mean delta t-stat: {abl_df[\"delta_t\"].mean():+.3f}')\n\n# Per-pair summary\nprint(f'\\n--- By tenor pair ---')\nfor fast, slow in TENOR_PAIRS:\n    pair_str = f'{fast}->{slow}'\n    pair_abl = abl_df[abl_df['pair'] == pair_str]\n    if len(pair_abl) > 0:\n        improved = (pair_abl['delta_t'] > 0).mean() * 100\n        mean_dt = pair_abl['delta_t'].mean()\n        print(f'  {pair_str}: improves {improved:.0f}% of cases, avg delta-t: {mean_dt:+.3f}')\n\nprint(f'\\nTop improvements (slow quiet adds most value):\\n')\ncols = ['pair', 'fast_signal', 'div_signal', 't_fast', 't_div', 'delta_t', 'n_fast', 'n_div', 'hit_div']\nprint(abl_df[cols].head(15).to_string(index=False, float_format='%.3f'))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# 5b. Ablation bar chart — grouped by tenor pair\ntop_pairs_abl = abl_df.head(min(15, len(abl_df)))\nif len(top_pairs_abl) > 0:\n    fig, ax = plt.subplots(figsize=(14, max(5, len(top_pairs_abl) * 0.45)))\n\n    y = range(len(top_pairs_abl))\n    labels = []\n    pair_colors = []\n    for _, r in top_pairs_abl.iterrows():\n        short = r['fast_signal'].replace('bull_', 'B:').replace('bear_', 'S:')\n        labels.append(f\"[{r['pair']}] {short}\")\n        pc = r['pair'].replace('->', '')\n        pair_colors.append(COLORS_PAIR.get(pc, '#2ecc71'))\n\n    ax.barh([i - 0.15 for i in y], top_pairs_abl['t_fast'].values, height=0.3,\n            color='#95a5a6', label='Fast-only', alpha=0.8)\n    for i, (_, r) in enumerate(top_pairs_abl.iterrows()):\n        pc = r['pair'].replace('->', '')\n        ax.barh(i + 0.15, r['t_div'], height=0.3,\n                color=COLORS_PAIR.get(pc, '#2ecc71'), alpha=0.8)\n\n    # Legend entries for pairs\n    from matplotlib.patches import Patch\n    handles = [Patch(color='#95a5a6', label='Fast-only')]\n    for fast, slow in TENOR_PAIRS:\n        pl = f'{fast}{slow}'\n        handles.append(Patch(color=COLORS_PAIR.get(pl, '#2ecc71'),\n                             label=f'{fast}->{slow} divergence'))\n\n    ax.set_yticks(list(y))\n    ax.set_yticklabels(labels, fontsize=8)\n    ax.set_xlabel('t-statistic (5d horizon)')\n    ax.axvline(1.96, color='red', linestyle='--', linewidth=0.8, label='p=0.05')\n    ax.axvline(0, color='black', linewidth=0.5)\n    ax.set_title('Ablation: Does the Slow Quiet Filter Improve the Signal?\\n'\n                 'Colored > Gray means quiet filter adds value', fontweight='bold')\n    ax.legend(handles=handles, loc='lower right', fontsize=8)\n    fig.tight_layout()\n    plt.show()\n\n    # Summary stats\n    for fast, slow in TENOR_PAIRS:\n        pair_str = f'{fast}->{slow}'\n        pair_abl = abl_df[abl_df['pair'] == pair_str]\n        if len(pair_abl) > 0:\n            improved = (pair_abl['delta_t'] > 0).mean() * 100\n            print(f'{pair_str}: slow quiet filter improves {improved:.0f}% of cases, '\n                  f'avg delta-t: {pair_abl[\"delta_t\"].mean():+.3f}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Optimal MA Window Deep-Dive\n",
    "\n",
    "Fix the best detection method and sweep the MA windows to find the sweet spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# 6a. Determine best method per pair and sweep fast-tenor window\nmethod_counts = {}\nfor _, row in div_results.head(30).iterrows():\n    try:\n        p = parse_signal_name(row['signal'])\n        m = p.get('method_fast', 'chg')\n        method_counts[m] = method_counts.get(m, 0) + 1\n    except (ValueError, IndexError, KeyError):\n        pass\n\nbest_method = max(method_counts, key=method_counts.get) if method_counts else 'chg'\nprint(f'Method frequency in top-30 divergence signals: {method_counts}')\nprint(f'Best fast detection method: {best_method}')\n\n# Compare t-stat vs fast window for each pair\nfig, axes = plt.subplots(1, len(TENOR_PAIRS), figsize=(6 * len(TENOR_PAIRS), 5))\nif len(TENOR_PAIRS) == 1:\n    axes = [axes]\nsweep_windows = MA_WINDOWS\n\nfor ax, (fast, slow) in zip(axes, TENOR_PAIRS):\n    pair_label = f'{fast}{slow}'\n    pair_color = COLORS_PAIR.get(pair_label, 'black')\n\n    for h_label, ls in [('5d', '-'), ('10d', '--')]:\n        t_stats = []\n        for w in sweep_windows:\n            prefix = f'bull_div_{pair_label}_{best_method}{w}d_p25'\n            matching = results_df[(results_df['signal'].str.startswith(prefix)) &\n                                  (results_df['horizon'] == h_label)]\n            if len(matching) > 0:\n                t_stats.append(matching['t_stat'].max())\n            else:\n                # Try bear too\n                prefix_b = f'bear_div_{pair_label}_{best_method}{w}d_p25'\n                matching_b = results_df[(results_df['signal'].str.startswith(prefix_b)) &\n                                        (results_df['horizon'] == h_label)]\n                t_stats.append(matching_b['t_stat'].max() if len(matching_b) > 0 else np.nan)\n\n        ax.plot(sweep_windows, t_stats, 'o-', color=pair_color, linewidth=2,\n                markersize=8, linestyle=ls, label=f'{h_label} horizon')\n\n    ax.axhline(1.96, color='red', linestyle='--', linewidth=0.8, alpha=0.5, label='p=0.05')\n    ax.axhline(0, color='gray', linewidth=0.5)\n    ax.set_xlabel(f'{fast} Detection Window (days)')\n    ax.set_ylabel('t-statistic')\n    ax.set_title(f'{fast}->{slow}: t-stat vs {fast} window\\n'\n                 f'(method={best_method}, threshold=p25)', fontweight='bold')\n    ax.legend(fontsize=9)\n    ax.set_xticks(sweep_windows)\n\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "# 6b. 2D heatmap: fast window x slow quiet window for best pair\n# Find which pair has the best overall signal\nbest_pair = None\nbest_pair_t = -999\nfor fast, slow in TENOR_PAIRS:\n    pair_label = f'{fast}{slow}'\n    pair_div_5d = div_results[(div_results['signal'].str.contains(f'_div_{pair_label}_')) &\n                              (div_results['horizon'] == '5d')]\n    if len(pair_div_5d) > 0 and pair_div_5d.iloc[0]['t_stat'] > best_pair_t:\n        best_pair_t = pair_div_5d.iloc[0]['t_stat']\n        best_pair = (fast, slow)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nif best_pair:\n    fast_bp, slow_bp = best_pair\n    pair_label_bp = f'{fast_bp}{slow_bp}'\n\n    for ax, (direction, h_label) in zip(axes, [('bull', '5d'), ('bear', '5d')]):\n        grid = np.full((len(sweep_windows), len(sweep_windows)), np.nan)\n        for i, w_fast in enumerate(sweep_windows):\n            for j, w_slow in enumerate(sweep_windows):\n                prefix = f'{direction}_div_{pair_label_bp}_{best_method}{w_fast}d_p25'\n                matching = results_df[\n                    (results_df['signal'].str.startswith(prefix)) &\n                    (results_df['signal'].str.contains(f'\\\\w+{w_slow}d', regex=True)) &\n                    (results_df['horizon'] == h_label)\n                ]\n                if len(matching) > 0:\n                    grid[i, j] = matching['t_stat'].max()\n\n        im = ax.imshow(grid, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=4)\n        ax.set_xticks(range(len(sweep_windows)))\n        ax.set_xticklabels([f'{w}d' for w in sweep_windows])\n        ax.set_yticks(range(len(sweep_windows)))\n        ax.set_yticklabels([f'{w}d' for w in sweep_windows])\n        ax.set_xlabel(f'{slow_bp} Quiet Window')\n        ax.set_ylabel(f'{fast_bp} Detection Window')\n        ax.set_title(f'{direction.upper()} {fast_bp}->{slow_bp}, {h_label}\\n'\n                     f't-stat (method={best_method})', fontweight='bold')\n        for i in range(len(sweep_windows)):\n            for j in range(len(sweep_windows)):\n                if not np.isnan(grid[i, j]):\n                    ax.text(j, i, f'{grid[i,j]:.1f}', ha='center', va='center',\n                            fontsize=8, fontweight='bold' if grid[i,j] > 1.96 else 'normal',\n                            color='white' if abs(grid[i,j]) > 2.5 else 'black')\n\n    plt.colorbar(im, ax=axes, shrink=0.8, label='t-statistic')\n    fig.suptitle(f'2D Grid Search: {fast_bp} Window x {slow_bp} Quiet Window ({pair_label_bp})',\n                 fontweight='bold')\nelse:\n    axes[0].text(0.5, 0.5, 'No divergence signals found', transform=axes[0].transAxes, ha='center')\n\nfig.tight_layout()\nplt.show()\n\n# Print best overall\nbest_overall = div_results.iloc[0] if len(div_results) > 0 else None\nif best_overall is not None:\n    print(f'\\nBest overall divergence signal: {best_overall[\"signal\"]}')\n    print(f'  Pair: {best_overall[\"pair\"]}, Horizon: {best_overall[\"horizon\"]}, '\n          f't={best_overall[\"t_stat\"]:.2f}, p={best_overall[\"p_value\"]:.4f}, '\n          f'hit={best_overall[\"hit_rate\"]:.0%}, n={best_overall[\"n\"]}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Event Study — Divergence Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "# 7a. Cumulative return paths — best divergence per pair vs fast-only\nbest_bull_div = div_results[div_results['direction'] == 'bull'].iloc[0]['signal'] if len(div_results[div_results['direction'] == 'bull']) > 0 else None\nbest_bear_div = div_results[div_results['direction'] == 'bear'].iloc[0]['signal'] if len(div_results[div_results['direction'] == 'bear']) > 0 else None\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\nevent_window = 21\n\nfor ax, (sig_name, label, color) in zip(axes,\n        [(best_bull_div, 'Bullish divergence', 'green'),\n         (best_bear_div, 'Bearish divergence', 'red')]):\n    if sig_name is None or sig_name not in divergence_signals:\n        ax.text(0.5, 0.5, 'No signal', transform=ax.transAxes, ha='center')\n        continue\n\n    # Find matching fast-only signal\n    try:\n        p = parse_signal_name(sig_name)\n        ft = p.get('fast_tenor', '1M')\n        method = p.get('method_fast', 'chg')\n        win = p.get('win_fast', 5)\n        thresh = p.get('threshold', 'p25')\n        name_only = f'{p[\"direction\"]}_{ft}only_{method}{win}d_{thresh}'\n    except (ValueError, IndexError, KeyError):\n        name_only = None\n\n    for sig, lbl, c, ls in [(sig_name, 'Divergence', color, '-'),\n                             (name_only, 'Fast-only', 'gray', '--')]:\n        if sig is None or sig not in divergence_signals:\n            continue\n        m, s = divergence_signals[sig]\n        m = m.fillna(False).astype(bool)\n        events = df.index[m]\n\n        paths = []\n        for idx in events:\n            loc = df.index.get_loc(idx)\n            if loc + event_window < len(df):\n                fwd = df['spot'].iloc[loc:loc + event_window + 1].values\n                if not np.any(np.isnan(fwd)):\n                    paths.append((fwd / fwd[0] - 1) * 100 * s)\n\n        if paths:\n            paths = np.array(paths)\n            avg = paths.mean(axis=0)\n            sem = paths.std(axis=0) / np.sqrt(len(paths))\n            days = range(event_window + 1)\n            ax.plot(days, avg, color=c, linewidth=2, linestyle=ls,\n                    label=f'{lbl} (n={len(paths)})')\n            ax.fill_between(days, avg - 1.96*sem, avg + 1.96*sem, alpha=0.1, color=c)\n\n    ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n    ax.set_xlabel('Days after signal')\n    ax.set_ylabel('Cumulative signed return (%)')\n    ax.set_title(f'{label}\\n(solid=divergence, dashed=fast-only)', fontweight='bold')\n    ax.legend(fontsize=9)\n\nfig.suptitle('Event Study: Divergence vs Fast-Only', fontweight='bold')\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": "# 7b. Decay profile for top 3 divergence signals\nfine_horizons = [1, 2, 3, 5, 7, 10, 14, 21]\nfor h in fine_horizons:\n    col = f'fwd_ret_{h}d_fine'\n    if col not in df.columns:\n        df[col] = df['spot'].shift(-h) / df['spot'] - 1\n\nseen = set()\ntop_div_signals = []\nfor _, row in div_results.iterrows():\n    if row['signal'] not in seen and len(top_div_signals) < 3:\n        top_div_signals.append(row['signal'])\n        seen.add(row['signal'])\n\nfig, ax = plt.subplots(figsize=(12, 6))\ncolors_decay = plt.cm.Set1(np.linspace(0, 0.5, max(1, len(top_div_signals))))\n\nfor sig_name, color in zip(top_div_signals, colors_decay):\n    if sig_name not in divergence_signals:\n        continue\n    mask, sign = divergence_signals[sig_name]\n    mask = mask.fillna(False).astype(bool)\n    events = df.index[mask]\n\n    edges = []\n    for h in fine_horizons:\n        rets = df.loc[events, f'fwd_ret_{h}d_fine'].dropna() * sign\n        edges.append(rets.mean() * 10000 if len(rets) > 3 else np.nan)\n\n    # Extract pair for label\n    try:\n        p = parse_signal_name(sig_name)\n        pair_str = p.get('pair', '')\n        short_name = f\"[{pair_str}] {sig_name.split('_div_')[1][:30]}\" if '_div_' in sig_name else sig_name[:35]\n    except (ValueError, IndexError, KeyError):\n        short_name = sig_name[:35]\n    ax.plot(fine_horizons, edges, 'o-', color=color, linewidth=1.5,\n            markersize=6, label=short_name)\n\nax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\nax.set_xlabel('Holding period (days)')\nax.set_ylabel('Mean signed return (bps)')\nax.set_title('Signal Decay: Edge vs Holding Period (top divergence signals)', fontweight='bold')\nax.legend(fontsize=8)\nax.set_xticks(fine_horizons)\nfig.tight_layout()\nplt.show()\n\nprint('Optimal holding period (peak edge):')\nfor sig_name in top_div_signals:\n    if sig_name not in divergence_signals:\n        continue\n    mask, sign = divergence_signals[sig_name]\n    mask = mask.fillna(False).astype(bool)\n    events = df.index[mask]\n    best_h, best_edge = 0, 0\n    for h in fine_horizons:\n        rets = df.loc[events, f'fwd_ret_{h}d_fine'].dropna() * sign\n        if len(rets) > 3 and rets.mean() > best_edge:\n            best_edge = rets.mean()\n            best_h = h\n    try:\n        p = parse_signal_name(sig_name)\n        pair_str = p.get('pair', '')\n    except (ValueError, IndexError, KeyError):\n        pair_str = ''\n    short = sig_name.replace('bull_div_', 'B:').replace('bear_div_', 'S:')[:40]\n    print(f'  [{pair_str}] {short}: peak at {best_h}d ({best_edge*10000:.1f}bps)')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Signal Magnitude — Does Size Matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": "# 8a. Tercile analysis: split by magnitude of fast-tenor move\nbest_sig = top_div_signals[0] if top_div_signals else None\n\nif best_sig and best_sig in divergence_signals:\n    mask, sign = divergence_signals[best_sig]\n    mask = mask.fillna(False).astype(bool)\n\n    try:\n        p = parse_signal_name(best_sig)\n        ft = p.get('fast_tenor', '1M')\n        method = p.get('method_fast', 'chg')\n        win = p.get('win_fast', 5)\n        col_fast = detection_cols.get((ft, method, win), f'rho_{ft}_chg5d')\n    except (ValueError, IndexError, KeyError):\n        col_fast = 'rho_1M_chg5d'\n\n    event_df = df.loc[mask, [col_fast, 'fwd_ret_5d', 'fwd_ret_10d']].dropna()\n\n    if len(event_df) >= 9:\n        event_df['magnitude'] = event_df[col_fast].abs()\n        event_df['tercile'] = pd.qcut(event_df['magnitude'], 3,\n                                       labels=['Small', 'Medium', 'Large'])\n\n        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n        for ax, h in zip(axes, ['5d', '10d']):\n            ret_col = f'fwd_ret_{h}'\n            means = event_df.groupby('tercile', observed=False)[ret_col].mean() * sign * 10000\n            counts = event_df.groupby('tercile', observed=False)[ret_col].count()\n            colors_t = ['#3498db', '#f39c12', '#e74c3c']\n            bars = ax.bar(range(3), means.values, color=colors_t)\n            ax.set_xticks(range(3))\n            ax.set_xticklabels(means.index)\n            ax.set_ylabel('Mean signed return (bps)')\n            ax.set_title(f'{h} forward return by {p.get(\"fast_tenor\",\"fast\")} move magnitude',\n                         fontweight='bold')\n            ax.axhline(0, color='black', linewidth=0.5)\n            for bar, n in zip(bars, counts.values):\n                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n                        f'n={n}', ha='center', va='bottom', fontsize=9)\n\n        fig.suptitle(f'Does Fast Tenor Move Size Matter? ({best_sig[:50]})', fontweight='bold')\n        fig.tight_layout()\n        plt.show()\n    else:\n        print(f'Insufficient events for tercile analysis (n={len(event_df)})')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": "# 8b. Continuous: fast-tenor magnitude vs forward return\nif best_sig and best_sig in divergence_signals:\n    mask, sign = divergence_signals[best_sig]\n    mask = mask.fillna(False).astype(bool)\n\n    try:\n        p = parse_signal_name(best_sig)\n        ft = p.get('fast_tenor', '1M')\n        method = p.get('method_fast', 'chg')\n        win = p.get('win_fast', 5)\n        col_fast = detection_cols.get((ft, method, win), f'rho_{ft}_chg5d')\n    except (ValueError, IndexError, KeyError):\n        col_fast = 'rho_1M_chg5d'\n\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    for ax, h in zip(axes, ['5d', '10d']):\n        ret_col = f'fwd_ret_{h}'\n        valid = df.loc[mask, [col_fast, ret_col]].dropna()\n        if len(valid) < 10:\n            ax.text(0.5, 0.5, f'n={len(valid)}', transform=ax.transAxes, ha='center')\n            continue\n        x = valid[col_fast].abs()\n        y = valid[ret_col] * sign * 100\n        ax.scatter(x, y, alpha=0.4, s=20, color='steelblue')\n        slope, intercept, r, p_val, se = stats.linregress(x, y)\n        x_line = np.linspace(x.min(), x.max(), 100)\n        ax.plot(x_line, slope * x_line + intercept, 'k-', linewidth=1.5)\n        ax.set_xlabel(f'|{ft} rho {method}{win}d|')\n        ax.set_ylabel(f'{h} signed return (%)')\n        ax.set_title(f'r={r:.3f}, p={p_val:.3f}, n={len(valid)}', fontsize=10)\n        ax.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n\n    fig.suptitle(f'Fast Tenor Move Magnitude vs Forward Return\\n'\n                 f'Positive slope = bigger divergence -> bigger spot move', fontweight='bold')\n    fig.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Alpha & Nu Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": "# 9a. Does adding alpha/nu improve the divergence signal?\nfor param in ['alpha', 'nu']:\n    for tenor in pair_tenors:\n        col = f'{param}_{tenor}'\n        if col in df.columns:\n            for N in [5, 10]:\n                chg_col = f'{col}_chg{N}d'\n                if chg_col not in df.columns:\n                    df[chg_col] = df[col].diff(N)\n\nif best_sig and best_sig in divergence_signals:\n    mask_base, sign = divergence_signals[best_sig]\n    mask_base = mask_base.fillna(False).astype(bool)\n\n    # Determine which fast tenor the best signal uses\n    try:\n        p = parse_signal_name(best_sig)\n        ft = p.get('fast_tenor', '1M')\n    except (ValueError, IndexError, KeyError):\n        ft = '1M'\n\n    print(f'=== ALPHA/NU CONFIRMATION (base: {best_sig[:60]}) ===\\n')\n    print(f'{\"Condition\":<45s} {\"5d ret\":>10s} {\"t\":>7s} {\"p\":>7s} {\"hit%\":>6s} {\"n\":>5s}')\n    print('-' * 85)\n\n    # Use the pair mask for this signal's fast tenor\n    pair_m = df[f'rho_{ft}'].notna()\n    configs = [('Base divergence only', mask_base)]\n\n    for N in [5, 10]:\n        acol = f'alpha_{ft}_chg{N}d'\n        if acol in df.columns:\n            vals = df.loc[pair_m, acol].dropna()\n            if len(vals) > 10:\n                thresh = vals.quantile(0.75)\n                configs.append((f'+ alpha_{ft} rises ({N}d, p75)', mask_base & (df[acol] > thresh)))\n\n    for N in [5, 10]:\n        ncol = f'nu_{ft}_chg{N}d'\n        if ncol in df.columns:\n            vals = df.loc[pair_m, ncol].dropna()\n            if len(vals) > 10:\n                thresh = vals.quantile(0.75)\n                configs.append((f'+ nu_{ft} rises ({N}d, p75)', mask_base & (df[ncol] > thresh)))\n\n    acol = f'alpha_{ft}_chg5d'\n    if acol in df.columns:\n        vals = df.loc[pair_m, acol].dropna()\n        if len(vals) > 10:\n            thresh = vals.quantile(0.25)\n            configs.append((f'+ alpha_{ft} falls (5d, p25)', mask_base & (df[acol] < thresh)))\n\n    for label, mask in configs:\n        rets = df.loc[mask, 'fwd_ret_5d'].dropna() * sign\n        if len(rets) >= 5:\n            t, p_val = stats.ttest_1samp(rets, 0)\n            hit = (rets > 0).mean()\n            print(f'{label:<45s} {rets.mean()*10000:>+9.1f}bps {t:>7.2f} {p_val:>7.3f} {hit:>5.0%} {len(rets):>5d}')\n        else:\n            print(f'{label:<45s}    too few events (n={len(rets)})')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Backtest — Best Divergence Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": "# 10a. Determine optimal hold period and run backtest\nHOLD_DAYS = 5\nif best_sig and best_sig in divergence_signals:\n    mask, sign = divergence_signals[best_sig]\n    mask = mask.fillna(False).astype(bool)\n    events = df.index[mask]\n    best_h, best_edge = 5, 0\n    for h in fine_horizons:\n        rets = df.loc[events, f'fwd_ret_{h}d_fine'].dropna() * sign\n        if len(rets) > 3 and rets.mean() > best_edge:\n            best_edge = rets.mean()\n            best_h = h\n    HOLD_DAYS = best_h\n    print(f'Optimal hold period: {HOLD_DAYS} days')\n\nCOST_PER_TRADE_PCT = 0.00005\n\nbt = df[['date', 'spot']].dropna().copy().reset_index(drop=True)\nbt['daily_ret'] = bt['spot'].pct_change()\nbt['position'] = 0.0\n\nbull_mask = pd.Series(False, index=df.index)\nbear_mask = pd.Series(False, index=df.index)\nif best_bull_div and best_bull_div in divergence_signals:\n    bull_mask = divergence_signals[best_bull_div][0].fillna(False).astype(bool)\nif best_bear_div and best_bear_div in divergence_signals:\n    bear_mask = divergence_signals[best_bear_div][0].fillna(False).astype(bool)\n\nhold_until_idx = -1\nfor i in range(len(bt)):\n    if i <= hold_until_idx:\n        bt.iloc[i, bt.columns.get_loc('position')] = bt.iloc[i-1, bt.columns.get_loc('position')]\n        continue\n    date_i = bt['date'].iloc[i]\n    if date_i in df['date'].values:\n        df_idx = df.index[df['date'] == date_i]\n        if len(df_idx) > 0:\n            idx = df_idx[0]\n            if idx in bull_mask.index and bull_mask.get(idx, False):\n                bt.iloc[i, bt.columns.get_loc('position')] = 1.0\n                hold_until_idx = min(i + HOLD_DAYS, len(bt) - 1)\n            elif idx in bear_mask.index and bear_mask.get(idx, False):\n                bt.iloc[i, bt.columns.get_loc('position')] = -1.0\n                hold_until_idx = min(i + HOLD_DAYS, len(bt) - 1)\n\nbt['signal_ret'] = bt['position'].shift(1) * bt['daily_ret']\nbt['pos_change'] = bt['position'].diff().abs()\nbt['cost'] = bt['pos_change'] * COST_PER_TRADE_PCT\nbt['net_ret'] = bt['signal_ret'] - bt['cost']\nbt['cum_gross'] = (1 + bt['signal_ret'].fillna(0)).cumprod()\nbt['cum_net'] = (1 + bt['net_ret'].fillna(0)).cumprod()\nbt['cum_bh'] = (1 + bt['daily_ret'].fillna(0)).cumprod()\n\nn_trades = (bt['pos_change'] > 0).sum()\nactive_days = (bt['position'] != 0).sum()\nsr_gross = bt['signal_ret'].mean() / bt['signal_ret'].std() * np.sqrt(252) if bt['signal_ret'].std() > 0 else 0\nsr_net = bt['net_ret'].mean() / bt['net_ret'].std() * np.sqrt(252) if bt['net_ret'].std() > 0 else 0\nmax_dd = (bt['cum_net'] / bt['cum_net'].cummax() - 1).min()\n\n# Identify pair info for the signals used\nbull_pair = 'n/a'\nbear_pair = 'n/a'\ntry:\n    if best_bull_div:\n        bp = parse_signal_name(best_bull_div)\n        bull_pair = bp.get('pair', 'n/a')\n    if best_bear_div:\n        bp = parse_signal_name(best_bear_div)\n        bear_pair = bp.get('pair', 'n/a')\nexcept (ValueError, IndexError, KeyError):\n    pass\n\nprint(f'\\n=== BACKTEST: Best Divergence Signal, hold {HOLD_DAYS}d ===')\nprint(f'  Bull signal [{bull_pair}]: {best_bull_div}')\nprint(f'  Bear signal [{bear_pair}]: {best_bear_div}')\nprint(f'  Trades:       {n_trades}')\nprint(f'  Active days:  {active_days} / {len(bt)} ({active_days/len(bt):.0%})')\nprint(f'  Gross Sharpe: {sr_gross:.2f}')\nprint(f'  Net Sharpe:   {sr_net:.2f}')\nprint(f'  Total gross:  {(bt[\"cum_gross\"].iloc[-1]-1)*100:+.2f}%')\nprint(f'  Total net:    {(bt[\"cum_net\"].iloc[-1]-1)*100:+.2f}%')\nprint(f'  Max drawdown: {max_dd*100:.2f}%')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10b. Equity curve\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8), sharex=True,\n",
    "                                gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "ax1.plot(bt['date'], (bt['cum_gross']-1)*100, color='blue', linewidth=1.2, label='Gross')\n",
    "ax1.plot(bt['date'], (bt['cum_net']-1)*100, color='darkblue', linewidth=1.5, label='Net (0.5pip)')\n",
    "ax1.plot(bt['date'], (bt['cum_bh']-1)*100, color='gray', linewidth=0.8, alpha=0.5, label='Buy & hold')\n",
    "ax1.axhline(0, color='black', linewidth=0.5)\n",
    "ax1.set_ylabel('Cumulative return (%)')\n",
    "ax1.set_title(f'GBPUSD Backtest: Divergence Signal, hold={HOLD_DAYS}d\\n'\n",
    "              f'Gross Sharpe={sr_gross:.2f}, Net Sharpe={sr_net:.2f}, Trades={n_trades}',\n",
    "              fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.fill_between(bt['date'], bt['position'], 0, alpha=0.4,\n",
    "                 where=bt['position'] > 0, color='green', label='Long')\n",
    "ax2.fill_between(bt['date'], bt['position'], 0, alpha=0.4,\n",
    "                 where=bt['position'] < 0, color='red', label='Short')\n",
    "ax2.set_ylabel('Position')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Robustness & Reality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11a. Sub-period consistency\n",
    "print('=== SUB-PERIOD CONSISTENCY ===\\n')\n",
    "mid_date = df['date'].median()\n",
    "first_half = df[df['date'] <= mid_date]\n",
    "second_half = df[df['date'] > mid_date]\n",
    "print(f'Period 1: {first_half[\"date\"].min().date()} to {first_half[\"date\"].max().date()} ({len(first_half)} days)')\n",
    "print(f'Period 2: {second_half[\"date\"].min().date()} to {second_half[\"date\"].max().date()} ({len(second_half)} days)')\n",
    "\n",
    "top_for_robustness = []\n",
    "seen_r = set()\n",
    "for _, row in div_results[div_results['horizon'] == '5d'].iterrows():\n",
    "    if row['signal'] not in seen_r and len(top_for_robustness) < 5:\n",
    "        top_for_robustness.append(row['signal'])\n",
    "        seen_r.add(row['signal'])\n",
    "\n",
    "print(f'\\n{\"Signal\":<50s} {\"P1\":>10s} {\"P2\":>10s} {\"Consistent?\":>12s}')\n",
    "print('-' * 85)\n",
    "\n",
    "for sig_name in top_for_robustness:\n",
    "    if sig_name not in divergence_signals:\n",
    "        continue\n",
    "    mask, sign = divergence_signals[sig_name]\n",
    "    mask = mask.fillna(False).astype(bool)\n",
    "    means = []\n",
    "    for half_df in [first_half, second_half]:\n",
    "        events = half_df.index[mask.reindex(half_df.index, fill_value=False)]\n",
    "        rets = half_df.loc[events, 'fwd_ret_5d'].dropna() * sign\n",
    "        means.append(rets.mean() * 10000 if len(rets) > 2 else np.nan)\n",
    "    consistent = 'YES' if (not np.isnan(means[0]) and not np.isnan(means[1])\n",
    "                           and means[0] * means[1] > 0) else 'NO'\n",
    "    p1 = f'{means[0]:+.1f}bps' if not np.isnan(means[0]) else 'n/a'\n",
    "    p2 = f'{means[1]:+.1f}bps' if not np.isnan(means[1]) else 'n/a'\n",
    "    short = sig_name[:48]\n",
    "    print(f'{short:<50s} {p1:>10s} {p2:>10s} {consistent:>12s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": "# 11b. Random signal comparison\nrng = np.random.RandomState(RANDOM_STATE)\nn_random = 1000\n\n# Use all dates that have spot data for the random baseline\nmask_any = df['spot'].notna()\nret_5d_vals = df.loc[mask_any, 'fwd_ret_5d'].dropna().values\n\nif best_sig and best_sig in divergence_signals:\n    m, s = divergence_signals[best_sig]\n    n_target = m.fillna(False).astype(bool).sum()\nelse:\n    n_target = 30\n\nrandom_tstats = []\nfor _ in range(n_random):\n    idx = rng.choice(len(ret_5d_vals), size=min(n_target, len(ret_5d_vals)), replace=False)\n    sample = ret_5d_vals[idx]\n    if np.std(sample) > 0:\n        t = np.mean(sample) / (np.std(sample) / np.sqrt(len(sample)))\n        random_tstats.append(abs(t))\n\nour_t = abs(div_results.iloc[0]['t_stat']) if len(div_results) > 0 else 0\npctile = (np.array(random_tstats) < our_t).mean() * 100\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.hist(random_tstats, bins=50, alpha=0.6, color='gray', edgecolor='black', linewidth=0.5)\nax.axvline(our_t, color='red', linewidth=2,\n           label=f'Our best (|t|={our_t:.2f}, {pctile:.0f}th pctile)')\nax.set_xlabel('|t-statistic| of random entry rules')\nax.set_ylabel('Count')\nax.set_title(f'Random Signal Comparison ({n_random} random, n={n_target})', fontweight='bold')\nax.legend()\nfig.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 12: Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": "print('=' * 70)\nprint('INVESTIGATION SUMMARY: GBP SKEW DIVERGENCE SIGNAL')\nprint('=' * 70)\n\nprint(f'\\n1. KEY FINDING (Section 2)')\nprint(f'   When a fast tenor moves but a slower tenor hasn\\'t yet, GBPUSD spot')\nprint(f'   moves in the direction implied by the fast tenor.')\n\nprint(f'\\n2. DATA')\nprint(f'   Currency: {CCY} ({PAIR})')\nprint(f'   Date range: {df[\"date\"].min().date()} to {df[\"date\"].max().date()}')\nfor fast, slow in TENOR_PAIRS:\n    n_overlap = mask_pair[(fast, slow)].sum()\n    print(f'   {fast}->{slow} overlap: {n_overlap} dates')\n\nif len(div_results) > 0:\n    n_tests_div = len(div_results)\n    n_sig_div = (div_results['p_value'] < 0.05).sum()\n    n_bonf_div = div_results['sig_bonf'].sum()\n\n    print(f'\\n3. DIVERGENCE SIGNAL GRID SEARCH ({n_tests_div} tests)')\n    print(f'   Significant at p<0.05: {n_sig_div}')\n    print(f'   After Bonferroni:      {n_bonf_div}')\n    print(f'   Expected false pos:    {n_tests_div * 0.05:.1f}')\n\n    # Per-pair best signals\n    print(f'\\n4. BEST SIGNAL PER TENOR PAIR')\n    div_5d_summary = div_results[div_results['horizon'] == '5d']\n    for fast, slow in TENOR_PAIRS:\n        pair_label = f'{fast}{slow}'\n        pair_best = div_5d_summary[div_5d_summary['signal'].str.contains(f'_div_{pair_label}_')]\n        if len(pair_best) > 0:\n            row = pair_best.iloc[0]\n            print(f'   {fast}->{slow}: t={row[\"t_stat\"]:.2f}, hit={row[\"hit_rate\"]:.0%}, '\n                  f'n={row[\"n\"]}, edge={row[\"mean_bps\"]:+.1f}bps')\n\n    print(f'\\n5. OVERALL BEST DIVERGENCE SIGNALS')\n    for i, (_, row) in enumerate(div_results.head(5).iterrows()):\n        flag = ' ***' if row.get('sig_bonf', False) else ''\n        print(f'   {i+1}. [{row.get(\"pair\",\"?\")}] {row[\"signal\"]}')\n        print(f'      {row[\"horizon\"]}: edge={row[\"mean_bps\"]:+.1f}bps, '\n              f'hit={row[\"hit_rate\"]:.0%}, t={row[\"t_stat\"]:.2f}, '\n              f'p={row[\"p_value\"]:.4f}, n={row[\"n\"]}{flag}')\n\nprint(f'\\n6. ABLATION: SLOW QUIET FILTER VALUE')\nif len(abl_df) > 0:\n    for fast, slow in TENOR_PAIRS:\n        pair_str = f'{fast}->{slow}'\n        pair_abl = abl_df[abl_df['pair'] == pair_str]\n        if len(pair_abl) > 0:\n            improved_pct = (pair_abl['delta_t'] > 0).mean() * 100\n            avg_delta = pair_abl['delta_t'].mean()\n            print(f'   {pair_str}: improves {improved_pct:.0f}% of cases, avg delta-t: {avg_delta:+.3f}')\n\nprint(f'\\n7. OPTIMAL TIMING')\nprint(f'   Hold period: {HOLD_DAYS} days')\nprint(f'   Best detection method: {best_method}')\n\nprint(f'\\n8. BACKTEST')\nprint(f'   Gross Sharpe: {sr_gross:.2f}')\nprint(f'   Net Sharpe:   {sr_net:.2f}')\nprint(f'   Max drawdown: {max_dd*100:.1f}%')\nprint(f'   Trades:       {n_trades}')\n\nprint(f'\\n9. KEY QUESTION: CAN 1W GET US IN EARLIER?')\n# Compare best 1W vs 1M based signals\nbest_1w = div_5d_summary[div_5d_summary['signal'].str.contains('_div_1W')]\nbest_1m = div_5d_summary[div_5d_summary['signal'].str.contains('_div_1M3M')]\nif len(best_1w) > 0 and len(best_1m) > 0:\n    t_1w = best_1w.iloc[0]['t_stat']\n    t_1m = best_1m.iloc[0]['t_stat']\n    if t_1w > t_1m:\n        print(f'   YES: Best 1W signal (t={t_1w:.2f}) beats best 1M->3M (t={t_1m:.2f})')\n    else:\n        print(f'   NO: Best 1M->3M (t={t_1m:.2f}) still beats best 1W signal (t={t_1w:.2f})')\n    print(f'   Best 1W: {best_1w.iloc[0][\"signal\"]}')\n    print(f'   Best 1M: {best_1m.iloc[0][\"signal\"]}')\nelif len(best_1w) > 0:\n    print(f'   1W signals found (best t={best_1w.iloc[0][\"t_stat\"]:.2f}) but no 1M->3M for comparison')\nelse:\n    print(f'   No 1W signals passed minimum event threshold')\n\nprint(f'\\n10. HONEST ASSESSMENT')\nif len(div_results) > 0:\n    if n_bonf_div > 0:\n        print(f'   STRONG: {n_bonf_div} signals survive Bonferroni.')\n    elif n_sig_div > n_tests_div * 0.05 * 2:\n        print(f'   PROMISING: {n_sig_div} significant (expected {n_tests_div*0.05:.1f}).')\n    else:\n        print(f'   CAUTIOUS: Signal count near chance level. Small samples remain a concern.')\n\nprint(f'\\n11. NEXT STEPS')\nprint(f'   - Apply to EUR (more 3M/6M data)')\nprint(f'   - Pool GBP+EUR for more statistical power')\nprint(f'   - Explore 2W tenor (different expiry phase from 1W)')\nprint(f'   - Fine-tune around the best MA window')\nprint(f'   - Paper trade with live data')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}